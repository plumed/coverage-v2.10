<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - plumed test coverage - metatensor/metatensor.cpp</title>
  <link rel="stylesheet" type="text/css" href="../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../index.html">top level</a> - <a href="index.html">metatensor</a> - metatensor.cpp<span style="font-size: 80%;"> (source / <a href="metatensor.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">plumed test coverage</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">16</td>
            <td class="headerCovTableEntry">24</td>
            <td class="headerCovTableEntryLo">66.7 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2024-10-23 18:13:10</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">1</td>
            <td class="headerCovTableEntry">5</td>
            <td class="headerCovTableEntryLo">20.0 %</td>
          </tr>
          <tr><td><img src="../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++</a>
<a name="2"><span class="lineNum">       2 </span>            : Copyright (c) 2024 The METATENSOR code team</a>
<a name="3"><span class="lineNum">       3 </span>            : (see the PEOPLE-METATENSOR file at the root of this folder for a list of names)</a>
<a name="4"><span class="lineNum">       4 </span>            : </a>
<a name="5"><span class="lineNum">       5 </span>            : See https://docs.metatensor.org/latest/ for more information about the</a>
<a name="6"><span class="lineNum">       6 </span>            : metatensor package that this module allows you to call from PLUMED.</a>
<a name="7"><span class="lineNum">       7 </span>            : </a>
<a name="8"><span class="lineNum">       8 </span>            : This file is part of METATENSOR-PLUMED module.</a>
<a name="9"><span class="lineNum">       9 </span>            : </a>
<a name="10"><span class="lineNum">      10 </span>            : The METATENSOR-PLUMED module is free software: you can redistribute it and/or modify</a>
<a name="11"><span class="lineNum">      11 </span>            : it under the terms of the GNU Lesser General Public License as published by</a>
<a name="12"><span class="lineNum">      12 </span>            : the Free Software Foundation, either version 3 of the License, or</a>
<a name="13"><span class="lineNum">      13 </span>            : (at your option) any later version.</a>
<a name="14"><span class="lineNum">      14 </span>            : </a>
<a name="15"><span class="lineNum">      15 </span>            : The METATENSOR-PLUMED module is distributed in the hope that it will be useful,</a>
<a name="16"><span class="lineNum">      16 </span>            : but WITHOUT ANY WARRANTY; without even the implied warranty of</a>
<a name="17"><span class="lineNum">      17 </span>            : MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the</a>
<a name="18"><span class="lineNum">      18 </span>            : GNU Lesser General Public License for more details.</a>
<a name="19"><span class="lineNum">      19 </span>            : </a>
<a name="20"><span class="lineNum">      20 </span>            : You should have received a copy of the GNU Lesser General Public License</a>
<a name="21"><span class="lineNum">      21 </span>            : along with the METATENSOR-PLUMED module. If not, see &lt;http://www.gnu.org/licenses/&gt;.</a>
<a name="22"><span class="lineNum">      22 </span>            : +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ */</a>
<a name="23"><span class="lineNum">      23 </span>            : </a>
<a name="24"><span class="lineNum">      24 </span>            : #include &quot;core/ActionAtomistic.h&quot;</a>
<a name="25"><span class="lineNum">      25 </span>            : #include &quot;core/ActionWithValue.h&quot;</a>
<a name="26"><span class="lineNum">      26 </span>            : #include &quot;core/ActionRegister.h&quot;</a>
<a name="27"><span class="lineNum">      27 </span>            : #include &quot;core/PlumedMain.h&quot;</a>
<a name="28"><span class="lineNum">      28 </span>            : </a>
<a name="29"><span class="lineNum">      29 </span>            : //+PLUMEDOC METATENSORMOD_COLVAR METATENSOR</a>
<a name="30"><span class="lineNum">      30 </span>            : /*</a>
<a name="31"><span class="lineNum">      31 </span>            : Use arbitrary machine learning models as collective variables.</a>
<a name="32"><span class="lineNum">      32 </span>            : </a>
<a name="33"><span class="lineNum">      33 </span>            : Note that this action requires the metatensor-torch library. Check the</a>
<a name="34"><span class="lineNum">      34 </span>            : instructions in the \ref METATENSORMOD page to enable this module.</a>
<a name="35"><span class="lineNum">      35 </span>            : </a>
<a name="36"><span class="lineNum">      36 </span>            : This action enables the use of fully custom machine learning models — based on</a>
<a name="37"><span class="lineNum">      37 </span>            : the [metatensor atomistic models][mts_models] interface — as collective</a>
<a name="38"><span class="lineNum">      38 </span>            : variables in PLUMED. Such machine learning model are typically written and</a>
<a name="39"><span class="lineNum">      39 </span>            : customized using Python code, and then exported to run within PLUMED as</a>
<a name="40"><span class="lineNum">      40 </span>            : [TorchScript], which is a subset of Python that can be executed by the C++ torch</a>
<a name="41"><span class="lineNum">      41 </span>            : library.</a>
<a name="42"><span class="lineNum">      42 </span>            : </a>
<a name="43"><span class="lineNum">      43 </span>            : Metatensor offers a way to define such models and pass data from PLUMED (or any</a>
<a name="44"><span class="lineNum">      44 </span>            : other simulation engine) to the model and back. For more information on how to</a>
<a name="45"><span class="lineNum">      45 </span>            : define such model, have a look at the [corresponding tutorials][mts_tutorials],</a>
<a name="46"><span class="lineNum">      46 </span>            : or at the code in `regtest/metatensor/`. Each of the Python scripts in this</a>
<a name="47"><span class="lineNum">      47 </span>            : directory defines a custom machine learning CV that can be used with PLUMED.</a>
<a name="48"><span class="lineNum">      48 </span>            : </a>
<a name="49"><span class="lineNum">      49 </span>            : \par Examples</a>
<a name="50"><span class="lineNum">      50 </span>            : </a>
<a name="51"><span class="lineNum">      51 </span>            : The following input shows how you can call metatensor and evaluate the model</a>
<a name="52"><span class="lineNum">      52 </span>            : that is described in the file `custom_cv.pt` from PLUMED.</a>
<a name="53"><span class="lineNum">      53 </span>            : </a>
<a name="54"><span class="lineNum">      54 </span>            : \plumedfile metatensor_cv: METATENSOR ... MODEL=custom_cv.pt</a>
<a name="55"><span class="lineNum">      55 </span>            : </a>
<a name="56"><span class="lineNum">      56 </span>            :     SPECIES1=1-26</a>
<a name="57"><span class="lineNum">      57 </span>            :     SPECIES2=27-62</a>
<a name="58"><span class="lineNum">      58 </span>            :     SPECIES3=63-76</a>
<a name="59"><span class="lineNum">      59 </span>            :     SPECIES_TO_TYPES=6,1,8</a>
<a name="60"><span class="lineNum">      60 </span>            : ...</a>
<a name="61"><span class="lineNum">      61 </span>            : \endplumedfile</a>
<a name="62"><span class="lineNum">      62 </span>            : </a>
<a name="63"><span class="lineNum">      63 </span>            : The numbered `SPECIES` labels are used to indicate the list of atoms that belong</a>
<a name="64"><span class="lineNum">      64 </span>            : to each atomic species in the system. The `SPECIES_TO_TYPE` keyword then</a>
<a name="65"><span class="lineNum">      65 </span>            : provides information on the atom type for each species. The first number here is</a>
<a name="66"><span class="lineNum">      66 </span>            : the atomic type of the atoms that have been specified using the `SPECIES1` flag,</a>
<a name="67"><span class="lineNum">      67 </span>            : the second number is the atomic number of the atoms that have been specified</a>
<a name="68"><span class="lineNum">      68 </span>            : using the `SPECIES2` flag and so on.</a>
<a name="69"><span class="lineNum">      69 </span>            : </a>
<a name="70"><span class="lineNum">      70 </span>            : `METATENSOR` action also accepts the following options:</a>
<a name="71"><span class="lineNum">      71 </span>            : </a>
<a name="72"><span class="lineNum">      72 </span>            : - `EXTENSIONS_DIRECTORY` should be the path to a directory containing</a>
<a name="73"><span class="lineNum">      73 </span>            :   TorchScript extensions (as shared libraries) that are required to load and</a>
<a name="74"><span class="lineNum">      74 </span>            :   execute the model. This matches the `collect_extensions` argument to</a>
<a name="75"><span class="lineNum">      75 </span>            :   `MetatensorAtomisticModel.export` in Python.</a>
<a name="76"><span class="lineNum">      76 </span>            : - `CHECK_CONSISTENCY` can be used to enable internal consistency checks;</a>
<a name="77"><span class="lineNum">      77 </span>            : - `SELECTED_ATOMS` can be used to signal the metatensor models that it should</a>
<a name="78"><span class="lineNum">      78 </span>            :   only run its calculation for the selected subset of atoms. The model still</a>
<a name="79"><span class="lineNum">      79 </span>            :   need to know about all the atoms in the system (through the `SPECIES`</a>
<a name="80"><span class="lineNum">      80 </span>            :   keyword); but this can be used to reduce the calculation cost. Note that the</a>
<a name="81"><span class="lineNum">      81 </span>            :   indices of the selected atoms should start at 1 in the PLUMED input file, but</a>
<a name="82"><span class="lineNum">      82 </span>            :   they will be translated to start at 0 when given to the model (i.e. in</a>
<a name="83"><span class="lineNum">      83 </span>            :   Python/TorchScript, the `forward` method will receive a `selected_atoms` which</a>
<a name="84"><span class="lineNum">      84 </span>            :   starts at 0)</a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span>            : Here is another example with all the possible keywords:</a>
<a name="87"><span class="lineNum">      87 </span>            : </a>
<a name="88"><span class="lineNum">      88 </span>            : \plumedfile soap: METATENSOR ... MODEL=soap.pt EXTENSION_DIRECTORY=extensions</a>
<a name="89"><span class="lineNum">      89 </span>            : CHECK_CONSISTENCY</a>
<a name="90"><span class="lineNum">      90 </span>            : </a>
<a name="91"><span class="lineNum">      91 </span>            :     SPECIES1=1-10</a>
<a name="92"><span class="lineNum">      92 </span>            :     SPECIES2=11-20</a>
<a name="93"><span class="lineNum">      93 </span>            :     SPECIES_TO_TYPES=8,13</a>
<a name="94"><span class="lineNum">      94 </span>            : </a>
<a name="95"><span class="lineNum">      95 </span>            :     # only run the calculation for the Aluminium (type 13) atoms, but</a>
<a name="96"><span class="lineNum">      96 </span>            :     # include the Oxygen (type 8) as potential neighbors.</a>
<a name="97"><span class="lineNum">      97 </span>            :     SELECTED_ATOMS=11-20</a>
<a name="98"><span class="lineNum">      98 </span>            : ...</a>
<a name="99"><span class="lineNum">      99 </span>            : \endplumedfile</a>
<a name="100"><span class="lineNum">     100 </span>            : </a>
<a name="101"><span class="lineNum">     101 </span>            : \par Collective variables and metatensor models</a>
<a name="102"><span class="lineNum">     102 </span>            : </a>
<a name="103"><span class="lineNum">     103 </span>            : PLUMED can use the [`&quot;features&quot;` output][features_output] of metatensor</a>
<a name="104"><span class="lineNum">     104 </span>            : atomistic models as a collective variables. Alternatively, the code also accepts</a>
<a name="105"><span class="lineNum">     105 </span>            : an output named `&quot;plumed::cv&quot;`, with the same metadata structure as the</a>
<a name="106"><span class="lineNum">     106 </span>            : `&quot;features&quot;` output.</a>
<a name="107"><span class="lineNum">     107 </span>            : </a>
<a name="108"><span class="lineNum">     108 </span>            : */ /*</a>
<a name="109"><span class="lineNum">     109 </span>            : </a>
<a name="110"><span class="lineNum">     110 </span>            : [TorchScript]: https://pytorch.org/docs/stable/jit.html</a>
<a name="111"><span class="lineNum">     111 </span>            : [mts_models]: https://docs.metatensor.org/latest/atomistic/index.html</a>
<a name="112"><span class="lineNum">     112 </span>            : [mts_tutorials]: https://docs.metatensor.org/latest/examples/atomistic/index.html</a>
<a name="113"><span class="lineNum">     113 </span>            : [mts_block]: https://docs.metatensor.org/latest/torch/reference/block.html</a>
<a name="114"><span class="lineNum">     114 </span>            : [features_output]: https://docs.metatensor.org/latest/examples/atomistic/outputs/features.html</a>
<a name="115"><span class="lineNum">     115 </span>            : */</a>
<a name="116"><span class="lineNum">     116 </span>            : //+ENDPLUMEDOC</a>
<a name="117"><span class="lineNum">     117 </span>            : </a>
<a name="118"><span class="lineNum">     118 </span>            : /*INDENT-OFF*/</a>
<a name="119"><span class="lineNum">     119 </span>            : #if !defined(__PLUMED_HAS_METATENSOR) || !defined(__PLUMED_HAS_LIBTORCH)</a>
<a name="120"><span class="lineNum">     120 </span>            : </a>
<a name="121"><span class="lineNum">     121 </span>            : namespace PLMD { namespace metatensor {</a>
<a name="122"><span class="lineNum">     122 </span>            : class MetatensorPlumedAction: public ActionAtomistic, public ActionWithValue {</a>
<a name="123"><span class="lineNum">     123 </span>            : public:</a>
<a name="124"><span class="lineNum">     124 </span>            :     static void registerKeywords(Keywords&amp; keys);</a>
<a name="125"><span class="lineNum">     125 </span><span class="lineNoCov">          0 :     explicit MetatensorPlumedAction(const ActionOptions&amp; options):</span></a>
<a name="126"><span class="lineNum">     126 </span>            :         Action(options),</a>
<a name="127"><span class="lineNum">     127 </span>            :         ActionAtomistic(options),</a>
<a name="128"><span class="lineNum">     128 </span><span class="lineNoCov">          0 :         ActionWithValue(options)</span></a>
<a name="129"><span class="lineNum">     129 </span>            :     {</a>
<a name="130"><span class="lineNum">     130 </span><span class="lineNoCov">          0 :         throw std::runtime_error(</span></a>
<a name="131"><span class="lineNum">     131 </span>            :             &quot;Can not use metatensor action without the corresponding libraries. \n&quot;</a>
<a name="132"><span class="lineNum">     132 </span>            :             &quot;Make sure to configure with `--enable-metatensor --enable-libtorch` &quot;</a>
<a name="133"><span class="lineNum">     133 </span>            :             &quot;and that the corresponding libraries are found&quot;</a>
<a name="134"><span class="lineNum">     134 </span><span class="lineNoCov">          0 :         );</span></a>
<a name="135"><span class="lineNum">     135 </span><span class="lineNoCov">          0 :     }</span></a>
<a name="136"><span class="lineNum">     136 </span>            : </a>
<a name="137"><span class="lineNum">     137 </span><span class="lineNoCov">          0 :     void calculate() override {}</span></a>
<a name="138"><span class="lineNum">     138 </span><span class="lineNoCov">          0 :     void apply() override {}</span></a>
<a name="139"><span class="lineNum">     139 </span><span class="lineNoCov">          0 :     unsigned getNumberOfDerivatives() override {return 0;}</span></a>
<a name="140"><span class="lineNum">     140 </span>            : };</a>
<a name="141"><span class="lineNum">     141 </span>            : </a>
<a name="142"><span class="lineNum">     142 </span>            : }} // namespace PLMD::metatensor</a>
<a name="143"><span class="lineNum">     143 </span>            : </a>
<a name="144"><span class="lineNum">     144 </span>            : #else</a>
<a name="145"><span class="lineNum">     145 </span>            : </a>
<a name="146"><span class="lineNum">     146 </span>            : #include &lt;type_traits&gt;</a>
<a name="147"><span class="lineNum">     147 </span>            : </a>
<a name="148"><span class="lineNum">     148 </span>            : #pragma GCC diagnostic push</a>
<a name="149"><span class="lineNum">     149 </span>            : #pragma GCC diagnostic ignored &quot;-Wpedantic&quot;</a>
<a name="150"><span class="lineNum">     150 </span>            : #pragma GCC diagnostic ignored &quot;-Wunused-parameter&quot;</a>
<a name="151"><span class="lineNum">     151 </span>            : #pragma GCC diagnostic ignored &quot;-Wfloat-equal&quot;</a>
<a name="152"><span class="lineNum">     152 </span>            : #pragma GCC diagnostic ignored &quot;-Wfloat-conversion&quot;</a>
<a name="153"><span class="lineNum">     153 </span>            : #pragma GCC diagnostic ignored &quot;-Wimplicit-float-conversion&quot;</a>
<a name="154"><span class="lineNum">     154 </span>            : #pragma GCC diagnostic ignored &quot;-Wimplicit-int-conversion&quot;</a>
<a name="155"><span class="lineNum">     155 </span>            : #pragma GCC diagnostic ignored &quot;-Wshorten-64-to-32&quot;</a>
<a name="156"><span class="lineNum">     156 </span>            : #pragma GCC diagnostic ignored &quot;-Wsign-conversion&quot;</a>
<a name="157"><span class="lineNum">     157 </span>            : #pragma GCC diagnostic ignored &quot;-Wold-style-cast&quot;</a>
<a name="158"><span class="lineNum">     158 </span>            : </a>
<a name="159"><span class="lineNum">     159 </span>            : #include &lt;torch/script.h&gt;</a>
<a name="160"><span class="lineNum">     160 </span>            : #include &lt;torch/version.h&gt;</a>
<a name="161"><span class="lineNum">     161 </span>            : #include &lt;torch/cuda.h&gt;</a>
<a name="162"><span class="lineNum">     162 </span>            : #if TORCH_VERSION_MAJOR &gt;= 2</a>
<a name="163"><span class="lineNum">     163 </span>            : #include &lt;torch/mps.h&gt;</a>
<a name="164"><span class="lineNum">     164 </span>            : #endif</a>
<a name="165"><span class="lineNum">     165 </span>            : </a>
<a name="166"><span class="lineNum">     166 </span>            : #pragma GCC diagnostic pop</a>
<a name="167"><span class="lineNum">     167 </span>            : </a>
<a name="168"><span class="lineNum">     168 </span>            : #include &lt;metatensor/torch.hpp&gt;</a>
<a name="169"><span class="lineNum">     169 </span>            : #include &lt;metatensor/torch/atomistic.hpp&gt;</a>
<a name="170"><span class="lineNum">     170 </span>            : </a>
<a name="171"><span class="lineNum">     171 </span>            : #include &quot;vesin.h&quot;</a>
<a name="172"><span class="lineNum">     172 </span>            : </a>
<a name="173"><span class="lineNum">     173 </span>            : </a>
<a name="174"><span class="lineNum">     174 </span>            : namespace PLMD {</a>
<a name="175"><span class="lineNum">     175 </span>            : namespace metatensor {</a>
<a name="176"><span class="lineNum">     176 </span>            : </a>
<a name="177"><span class="lineNum">     177 </span>            : // We will cast Vector/Tensor to pointers to arrays and doubles, so let's make</a>
<a name="178"><span class="lineNum">     178 </span>            : // sure this is legal to do</a>
<a name="179"><span class="lineNum">     179 </span>            : static_assert(std::is_standard_layout&lt;PLMD::Vector&gt;::value);</a>
<a name="180"><span class="lineNum">     180 </span>            : static_assert(sizeof(PLMD::Vector) == sizeof(std::array&lt;double, 3&gt;));</a>
<a name="181"><span class="lineNum">     181 </span>            : static_assert(alignof(PLMD::Vector) == alignof(std::array&lt;double, 3&gt;));</a>
<a name="182"><span class="lineNum">     182 </span>            : </a>
<a name="183"><span class="lineNum">     183 </span>            : static_assert(std::is_standard_layout&lt;PLMD::Tensor&gt;::value);</a>
<a name="184"><span class="lineNum">     184 </span>            : static_assert(sizeof(PLMD::Tensor) == sizeof(std::array&lt;std::array&lt;double, 3&gt;, 3&gt;));</a>
<a name="185"><span class="lineNum">     185 </span>            : static_assert(alignof(PLMD::Tensor) == alignof(std::array&lt;std::array&lt;double, 3&gt;, 3&gt;));</a>
<a name="186"><span class="lineNum">     186 </span>            : </a>
<a name="187"><span class="lineNum">     187 </span>            : class MetatensorPlumedAction: public ActionAtomistic, public ActionWithValue {</a>
<a name="188"><span class="lineNum">     188 </span>            : public:</a>
<a name="189"><span class="lineNum">     189 </span>            :     static void registerKeywords(Keywords&amp; keys);</a>
<a name="190"><span class="lineNum">     190 </span>            :     explicit MetatensorPlumedAction(const ActionOptions&amp;);</a>
<a name="191"><span class="lineNum">     191 </span>            : </a>
<a name="192"><span class="lineNum">     192 </span>            :     void calculate() override;</a>
<a name="193"><span class="lineNum">     193 </span>            :     void apply() override;</a>
<a name="194"><span class="lineNum">     194 </span>            :     unsigned getNumberOfDerivatives() override;</a>
<a name="195"><span class="lineNum">     195 </span>            : </a>
<a name="196"><span class="lineNum">     196 </span>            : private:</a>
<a name="197"><span class="lineNum">     197 </span>            :     // fill this-&gt;system_ according to the current PLUMED data</a>
<a name="198"><span class="lineNum">     198 </span>            :     void createSystem();</a>
<a name="199"><span class="lineNum">     199 </span>            :     // compute a neighbor list following metatensor format, using data from PLUMED</a>
<a name="200"><span class="lineNum">     200 </span>            :     metatensor_torch::TorchTensorBlock computeNeighbors(</a>
<a name="201"><span class="lineNum">     201 </span>            :         metatensor_torch::NeighborListOptions request,</a>
<a name="202"><span class="lineNum">     202 </span>            :         const std::vector&lt;PLMD::Vector&gt;&amp; positions,</a>
<a name="203"><span class="lineNum">     203 </span>            :         const PLMD::Tensor&amp; cell</a>
<a name="204"><span class="lineNum">     204 </span>            :     );</a>
<a name="205"><span class="lineNum">     205 </span>            : </a>
<a name="206"><span class="lineNum">     206 </span>            :     // execute the model for the given system</a>
<a name="207"><span class="lineNum">     207 </span>            :     metatensor_torch::TorchTensorBlock executeModel(metatensor_torch::System system);</a>
<a name="208"><span class="lineNum">     208 </span>            : </a>
<a name="209"><span class="lineNum">     209 </span>            :     torch::jit::Module model_;</a>
<a name="210"><span class="lineNum">     210 </span>            : </a>
<a name="211"><span class="lineNum">     211 </span>            :     metatensor_torch::ModelCapabilities capabilities_;</a>
<a name="212"><span class="lineNum">     212 </span>            :     std::string model_output_;</a>
<a name="213"><span class="lineNum">     213 </span>            : </a>
<a name="214"><span class="lineNum">     214 </span>            :     // neighbor lists requests made by the model</a>
<a name="215"><span class="lineNum">     215 </span>            :     std::vector&lt;metatensor_torch::NeighborListOptions&gt; nl_requests_;</a>
<a name="216"><span class="lineNum">     216 </span>            : </a>
<a name="217"><span class="lineNum">     217 </span>            :     // dtype/device to use to execute the model</a>
<a name="218"><span class="lineNum">     218 </span>            :     torch::ScalarType dtype_;</a>
<a name="219"><span class="lineNum">     219 </span>            :     torch::Device device_;</a>
<a name="220"><span class="lineNum">     220 </span>            : </a>
<a name="221"><span class="lineNum">     221 </span>            :     torch::Tensor atomic_types_;</a>
<a name="222"><span class="lineNum">     222 </span>            :     // store the strain to be able to compute the virial with autograd</a>
<a name="223"><span class="lineNum">     223 </span>            :     torch::Tensor strain_;</a>
<a name="224"><span class="lineNum">     224 </span>            : </a>
<a name="225"><span class="lineNum">     225 </span>            :     metatensor_torch::System system_;</a>
<a name="226"><span class="lineNum">     226 </span>            :     metatensor_torch::ModelEvaluationOptions evaluations_options_;</a>
<a name="227"><span class="lineNum">     227 </span>            :     bool check_consistency_;</a>
<a name="228"><span class="lineNum">     228 </span>            : </a>
<a name="229"><span class="lineNum">     229 </span>            :     metatensor_torch::TorchTensorMap output_;</a>
<a name="230"><span class="lineNum">     230 </span>            :     // shape of the output of this model</a>
<a name="231"><span class="lineNum">     231 </span>            :     unsigned n_samples_;</a>
<a name="232"><span class="lineNum">     232 </span>            :     unsigned n_properties_;</a>
<a name="233"><span class="lineNum">     233 </span>            : };</a>
<a name="234"><span class="lineNum">     234 </span>            : </a>
<a name="235"><span class="lineNum">     235 </span>            : </a>
<a name="236"><span class="lineNum">     236 </span>            : MetatensorPlumedAction::MetatensorPlumedAction(const ActionOptions&amp; options):</a>
<a name="237"><span class="lineNum">     237 </span>            :     Action(options),</a>
<a name="238"><span class="lineNum">     238 </span>            :     ActionAtomistic(options),</a>
<a name="239"><span class="lineNum">     239 </span>            :     ActionWithValue(options),</a>
<a name="240"><span class="lineNum">     240 </span>            :     device_(torch::kCPU)</a>
<a name="241"><span class="lineNum">     241 </span>            : {</a>
<a name="242"><span class="lineNum">     242 </span>            :     if (metatensor_torch::version().find(&quot;0.5.&quot;) != 0) {</a>
<a name="243"><span class="lineNum">     243 </span>            :         this-&gt;error(</a>
<a name="244"><span class="lineNum">     244 </span>            :             &quot;this code requires version 0.5.x of metatensor-torch, got version &quot; +</a>
<a name="245"><span class="lineNum">     245 </span>            :             metatensor_torch::version()</a>
<a name="246"><span class="lineNum">     246 </span>            :         );</a>
<a name="247"><span class="lineNum">     247 </span>            :     }</a>
<a name="248"><span class="lineNum">     248 </span>            : </a>
<a name="249"><span class="lineNum">     249 </span>            :     // first, load the model</a>
<a name="250"><span class="lineNum">     250 </span>            :     std::string extensions_directory_str;</a>
<a name="251"><span class="lineNum">     251 </span>            :     this-&gt;parse(&quot;EXTENSIONS_DIRECTORY&quot;, extensions_directory_str);</a>
<a name="252"><span class="lineNum">     252 </span>            : </a>
<a name="253"><span class="lineNum">     253 </span>            :     torch::optional&lt;std::string&gt; extensions_directory = torch::nullopt;</a>
<a name="254"><span class="lineNum">     254 </span>            :     if (!extensions_directory_str.empty()) {</a>
<a name="255"><span class="lineNum">     255 </span>            :         extensions_directory = std::move(extensions_directory_str);</a>
<a name="256"><span class="lineNum">     256 </span>            :     }</a>
<a name="257"><span class="lineNum">     257 </span>            : </a>
<a name="258"><span class="lineNum">     258 </span>            :     std::string model_path;</a>
<a name="259"><span class="lineNum">     259 </span>            :     this-&gt;parse(&quot;MODEL&quot;, model_path);</a>
<a name="260"><span class="lineNum">     260 </span>            : </a>
<a name="261"><span class="lineNum">     261 </span>            :     try {</a>
<a name="262"><span class="lineNum">     262 </span>            :         this-&gt;model_ = metatensor_torch::load_atomistic_model(model_path, extensions_directory);</a>
<a name="263"><span class="lineNum">     263 </span>            :     } catch (const std::exception&amp; e) {</a>
<a name="264"><span class="lineNum">     264 </span>            :         this-&gt;error(&quot;failed to load model at '&quot; + model_path + &quot;': &quot; + e.what());</a>
<a name="265"><span class="lineNum">     265 </span>            :     }</a>
<a name="266"><span class="lineNum">     266 </span>            : </a>
<a name="267"><span class="lineNum">     267 </span>            :     // extract information from the model</a>
<a name="268"><span class="lineNum">     268 </span>            :     auto metadata = this-&gt;model_.run_method(&quot;metadata&quot;).toCustomClass&lt;metatensor_torch::ModelMetadataHolder&gt;();</a>
<a name="269"><span class="lineNum">     269 </span>            :     this-&gt;capabilities_ = this-&gt;model_.run_method(&quot;capabilities&quot;).toCustomClass&lt;metatensor_torch::ModelCapabilitiesHolder&gt;();</a>
<a name="270"><span class="lineNum">     270 </span>            :     auto requests_ivalue = this-&gt;model_.run_method(&quot;requested_neighbor_lists&quot;);</a>
<a name="271"><span class="lineNum">     271 </span>            :     for (auto request_ivalue: requests_ivalue.toList()) {</a>
<a name="272"><span class="lineNum">     272 </span>            :         auto request = request_ivalue.get().toCustomClass&lt;metatensor_torch::NeighborListOptionsHolder&gt;();</a>
<a name="273"><span class="lineNum">     273 </span>            :         this-&gt;nl_requests_.push_back(request);</a>
<a name="274"><span class="lineNum">     274 </span>            :     }</a>
<a name="275"><span class="lineNum">     275 </span>            : </a>
<a name="276"><span class="lineNum">     276 </span>            :     log.printf(&quot;\n%s\n&quot;, metadata-&gt;print().c_str());</a>
<a name="277"><span class="lineNum">     277 </span>            :     // add the model references to PLUMED citation handling mechanism</a>
<a name="278"><span class="lineNum">     278 </span>            :     for (const auto&amp; it: metadata-&gt;references) {</a>
<a name="279"><span class="lineNum">     279 </span>            :         for (const auto&amp; ref: it.value()) {</a>
<a name="280"><span class="lineNum">     280 </span>            :             this-&gt;cite(ref);</a>
<a name="281"><span class="lineNum">     281 </span>            :         }</a>
<a name="282"><span class="lineNum">     282 </span>            :     }</a>
<a name="283"><span class="lineNum">     283 </span>            : </a>
<a name="284"><span class="lineNum">     284 </span>            :     // parse the atomic types from the input file</a>
<a name="285"><span class="lineNum">     285 </span>            :     std::vector&lt;int32_t&gt; atomic_types;</a>
<a name="286"><span class="lineNum">     286 </span>            :     std::vector&lt;int32_t&gt; species_to_types;</a>
<a name="287"><span class="lineNum">     287 </span>            :     this-&gt;parseVector(&quot;SPECIES_TO_TYPES&quot;, species_to_types);</a>
<a name="288"><span class="lineNum">     288 </span>            :     bool has_custom_types = !species_to_types.empty();</a>
<a name="289"><span class="lineNum">     289 </span>            : </a>
<a name="290"><span class="lineNum">     290 </span>            :     std::vector&lt;AtomNumber&gt; all_atoms;</a>
<a name="291"><span class="lineNum">     291 </span>            :     this-&gt;parseAtomList(&quot;SPECIES&quot;, all_atoms);</a>
<a name="292"><span class="lineNum">     292 </span>            : </a>
<a name="293"><span class="lineNum">     293 </span>            :     size_t n_species = 0;</a>
<a name="294"><span class="lineNum">     294 </span>            :     if (all_atoms.empty()) {</a>
<a name="295"><span class="lineNum">     295 </span>            :         std::vector&lt;AtomNumber&gt; t;</a>
<a name="296"><span class="lineNum">     296 </span>            :         int i = 0;</a>
<a name="297"><span class="lineNum">     297 </span>            :         while (true) {</a>
<a name="298"><span class="lineNum">     298 </span>            :             i += 1;</a>
<a name="299"><span class="lineNum">     299 </span>            :             this-&gt;parseAtomList(&quot;SPECIES&quot;, i, t);</a>
<a name="300"><span class="lineNum">     300 </span>            :             if (t.empty()) {</a>
<a name="301"><span class="lineNum">     301 </span>            :                 break;</a>
<a name="302"><span class="lineNum">     302 </span>            :             }</a>
<a name="303"><span class="lineNum">     303 </span>            : </a>
<a name="304"><span class="lineNum">     304 </span>            :             int32_t type = i;</a>
<a name="305"><span class="lineNum">     305 </span>            :             if (has_custom_types) {</a>
<a name="306"><span class="lineNum">     306 </span>            :                 if (species_to_types.size() &lt; static_cast&lt;size_t&gt;(i)) {</a>
<a name="307"><span class="lineNum">     307 </span>            :                     this-&gt;error(</a>
<a name="308"><span class="lineNum">     308 </span>            :                         &quot;SPECIES_TO_TYPES is too small, it should have one entry &quot;</a>
<a name="309"><span class="lineNum">     309 </span>            :                         &quot;for each species (we have at least &quot; + std::to_string(i) +</a>
<a name="310"><span class="lineNum">     310 </span>            :                         &quot; species and &quot; + std::to_string(species_to_types.size()) +</a>
<a name="311"><span class="lineNum">     311 </span>            :                         &quot;entries in SPECIES_TO_TYPES)&quot;</a>
<a name="312"><span class="lineNum">     312 </span>            :                     );</a>
<a name="313"><span class="lineNum">     313 </span>            :                 }</a>
<a name="314"><span class="lineNum">     314 </span>            : </a>
<a name="315"><span class="lineNum">     315 </span>            :                 type = species_to_types[static_cast&lt;size_t&gt;(i - 1)];</a>
<a name="316"><span class="lineNum">     316 </span>            :             }</a>
<a name="317"><span class="lineNum">     317 </span>            : </a>
<a name="318"><span class="lineNum">     318 </span>            :             log.printf(&quot;  atoms with type %d are: &quot;, type);</a>
<a name="319"><span class="lineNum">     319 </span>            :             for(unsigned j=0; j&lt;t.size(); j++) {</a>
<a name="320"><span class="lineNum">     320 </span>            :                 log.printf(&quot;%d &quot;, t[j]);</a>
<a name="321"><span class="lineNum">     321 </span>            :                 all_atoms.push_back(t[j]);</a>
<a name="322"><span class="lineNum">     322 </span>            :                 atomic_types.push_back(type);</a>
<a name="323"><span class="lineNum">     323 </span>            :             }</a>
<a name="324"><span class="lineNum">     324 </span>            :             log.printf(&quot;\n&quot;); t.resize(0);</a>
<a name="325"><span class="lineNum">     325 </span>            : </a>
<a name="326"><span class="lineNum">     326 </span>            :             n_species += 1;</a>
<a name="327"><span class="lineNum">     327 </span>            :         }</a>
<a name="328"><span class="lineNum">     328 </span>            :     } else {</a>
<a name="329"><span class="lineNum">     329 </span>            :         n_species = 1;</a>
<a name="330"><span class="lineNum">     330 </span>            : </a>
<a name="331"><span class="lineNum">     331 </span>            :         int32_t type = 1;</a>
<a name="332"><span class="lineNum">     332 </span>            :         if (has_custom_types) {</a>
<a name="333"><span class="lineNum">     333 </span>            :             type = species_to_types[0];</a>
<a name="334"><span class="lineNum">     334 </span>            :         }</a>
<a name="335"><span class="lineNum">     335 </span>            :         atomic_types.resize(all_atoms.size(), type);</a>
<a name="336"><span class="lineNum">     336 </span>            :     }</a>
<a name="337"><span class="lineNum">     337 </span>            : </a>
<a name="338"><span class="lineNum">     338 </span>            :     if (has_custom_types &amp;&amp; species_to_types.size() != n_species) {</a>
<a name="339"><span class="lineNum">     339 </span>            :         this-&gt;warning(</a>
<a name="340"><span class="lineNum">     340 </span>            :             &quot;SPECIES_TO_TYPES contains more entries (&quot; +</a>
<a name="341"><span class="lineNum">     341 </span>            :             std::to_string(species_to_types.size()) +</a>
<a name="342"><span class="lineNum">     342 </span>            :             &quot;) than there where species (&quot; + std::to_string(n_species) + &quot;)&quot;</a>
<a name="343"><span class="lineNum">     343 </span>            :         );</a>
<a name="344"><span class="lineNum">     344 </span>            :     }</a>
<a name="345"><span class="lineNum">     345 </span>            : </a>
<a name="346"><span class="lineNum">     346 </span>            :     this-&gt;atomic_types_ = torch::tensor(std::move(atomic_types));</a>
<a name="347"><span class="lineNum">     347 </span>            :     this-&gt;requestAtoms(all_atoms);</a>
<a name="348"><span class="lineNum">     348 </span>            : </a>
<a name="349"><span class="lineNum">     349 </span>            :     this-&gt;check_consistency_ = false;</a>
<a name="350"><span class="lineNum">     350 </span>            :     this-&gt;parseFlag(&quot;CHECK_CONSISTENCY&quot;, this-&gt;check_consistency_);</a>
<a name="351"><span class="lineNum">     351 </span>            :     if (this-&gt;check_consistency_) {</a>
<a name="352"><span class="lineNum">     352 </span>            :         log.printf(&quot;  checking for internal consistency of the model\n&quot;);</a>
<a name="353"><span class="lineNum">     353 </span>            :     }</a>
<a name="354"><span class="lineNum">     354 </span>            : </a>
<a name="355"><span class="lineNum">     355 </span>            :     // create evaluation options for the model. These won't change during the</a>
<a name="356"><span class="lineNum">     356 </span>            :     // simulation, so we initialize them once here.</a>
<a name="357"><span class="lineNum">     357 </span>            :     evaluations_options_ = torch::make_intrusive&lt;metatensor_torch::ModelEvaluationOptionsHolder&gt;();</a>
<a name="358"><span class="lineNum">     358 </span>            :     evaluations_options_-&gt;set_length_unit(getUnits().getLengthString());</a>
<a name="359"><span class="lineNum">     359 </span>            : </a>
<a name="360"><span class="lineNum">     360 </span>            :     auto outputs = this-&gt;capabilities_-&gt;outputs();</a>
<a name="361"><span class="lineNum">     361 </span>            :     if (outputs.contains(&quot;features&quot;)) {</a>
<a name="362"><span class="lineNum">     362 </span>            :         this-&gt;model_output_ = &quot;features&quot;;</a>
<a name="363"><span class="lineNum">     363 </span>            :     }</a>
<a name="364"><span class="lineNum">     364 </span>            : </a>
<a name="365"><span class="lineNum">     365 </span>            :     if (outputs.contains(&quot;plumed::cv&quot;)) {</a>
<a name="366"><span class="lineNum">     366 </span>            :         if (outputs.contains(&quot;features&quot;)) {</a>
<a name="367"><span class="lineNum">     367 </span>            :             this-&gt;warning(</a>
<a name="368"><span class="lineNum">     368 </span>            :                 &quot;this model exposes both 'features' and 'plumed::cv' outputs, &quot;</a>
<a name="369"><span class="lineNum">     369 </span>            :                 &quot;we will use 'features'. 'plumed::cv' is deprecated, please &quot;</a>
<a name="370"><span class="lineNum">     370 </span>            :                 &quot;remove it from your models&quot;</a>
<a name="371"><span class="lineNum">     371 </span>            :             );</a>
<a name="372"><span class="lineNum">     372 </span>            :         } else {</a>
<a name="373"><span class="lineNum">     373 </span>            :             this-&gt;warning(</a>
<a name="374"><span class="lineNum">     374 </span>            :                 &quot;this model is using 'plumed::cv' output, which is deprecated. &quot;</a>
<a name="375"><span class="lineNum">     375 </span>            :                 &quot;Please replace it with a 'features' output&quot;</a>
<a name="376"><span class="lineNum">     376 </span>            :             );</a>
<a name="377"><span class="lineNum">     377 </span>            :             this-&gt;model_output_ = &quot;plumed::cv&quot;;</a>
<a name="378"><span class="lineNum">     378 </span>            :         }</a>
<a name="379"><span class="lineNum">     379 </span>            :     }</a>
<a name="380"><span class="lineNum">     380 </span>            : </a>
<a name="381"><span class="lineNum">     381 </span>            : </a>
<a name="382"><span class="lineNum">     382 </span>            :     if (this-&gt;model_output_.empty()) {</a>
<a name="383"><span class="lineNum">     383 </span>            :         auto existing_outputs = std::vector&lt;std::string&gt;();</a>
<a name="384"><span class="lineNum">     384 </span>            :         for (const auto&amp; it: this-&gt;capabilities_-&gt;outputs()) {</a>
<a name="385"><span class="lineNum">     385 </span>            :             existing_outputs.push_back(it.key());</a>
<a name="386"><span class="lineNum">     386 </span>            :         }</a>
<a name="387"><span class="lineNum">     387 </span>            : </a>
<a name="388"><span class="lineNum">     388 </span>            :         this-&gt;error(</a>
<a name="389"><span class="lineNum">     389 </span>            :             &quot;expected 'features' or 'plumed::cv' in the capabilities of the model, &quot;</a>
<a name="390"><span class="lineNum">     390 </span>            :             &quot;could not find it. the following outputs exist: &quot; + torch::str(existing_outputs)</a>
<a name="391"><span class="lineNum">     391 </span>            :         );</a>
<a name="392"><span class="lineNum">     392 </span>            :     }</a>
<a name="393"><span class="lineNum">     393 </span>            : </a>
<a name="394"><span class="lineNum">     394 </span>            :     auto output = torch::make_intrusive&lt;metatensor_torch::ModelOutputHolder&gt;();</a>
<a name="395"><span class="lineNum">     395 </span>            :     // this output has no quantity or unit to set</a>
<a name="396"><span class="lineNum">     396 </span>            : </a>
<a name="397"><span class="lineNum">     397 </span>            :     output-&gt;per_atom = this-&gt;capabilities_-&gt;outputs().at(this-&gt;model_output_)-&gt;per_atom;</a>
<a name="398"><span class="lineNum">     398 </span>            :     // we are using torch autograd system to compute gradients,</a>
<a name="399"><span class="lineNum">     399 </span>            :     // so we don't need any explicit gradients.</a>
<a name="400"><span class="lineNum">     400 </span>            :     output-&gt;explicit_gradients = {};</a>
<a name="401"><span class="lineNum">     401 </span>            :     evaluations_options_-&gt;outputs.insert(this-&gt;model_output_, output);</a>
<a name="402"><span class="lineNum">     402 </span>            : </a>
<a name="403"><span class="lineNum">     403 </span>            :     // Determine which device we should use based on user input, what the model</a>
<a name="404"><span class="lineNum">     404 </span>            :     // supports and what's available</a>
<a name="405"><span class="lineNum">     405 </span>            :     auto available_devices = std::vector&lt;torch::Device&gt;();</a>
<a name="406"><span class="lineNum">     406 </span>            :     for (const auto&amp; device: this-&gt;capabilities_-&gt;supported_devices) {</a>
<a name="407"><span class="lineNum">     407 </span>            :         if (device == &quot;cpu&quot;) {</a>
<a name="408"><span class="lineNum">     408 </span>            :             available_devices.push_back(torch::kCPU);</a>
<a name="409"><span class="lineNum">     409 </span>            :         } else if (device == &quot;cuda&quot;) {</a>
<a name="410"><span class="lineNum">     410 </span>            :             if (torch::cuda::is_available()) {</a>
<a name="411"><span class="lineNum">     411 </span>            :                 available_devices.push_back(torch::Device(&quot;cuda&quot;));</a>
<a name="412"><span class="lineNum">     412 </span>            :             }</a>
<a name="413"><span class="lineNum">     413 </span>            :         } else if (device == &quot;mps&quot;) {</a>
<a name="414"><span class="lineNum">     414 </span>            :             #if TORCH_VERSION_MAJOR &gt;= 2</a>
<a name="415"><span class="lineNum">     415 </span>            :             if (torch::mps::is_available()) {</a>
<a name="416"><span class="lineNum">     416 </span>            :                 available_devices.push_back(torch::Device(&quot;mps&quot;));</a>
<a name="417"><span class="lineNum">     417 </span>            :             }</a>
<a name="418"><span class="lineNum">     418 </span>            :             #endif</a>
<a name="419"><span class="lineNum">     419 </span>            :         } else {</a>
<a name="420"><span class="lineNum">     420 </span>            :             this-&gt;warning(</a>
<a name="421"><span class="lineNum">     421 </span>            :                 &quot;the model declared support for unknown device '&quot; + device +</a>
<a name="422"><span class="lineNum">     422 </span>            :                 &quot;', it will be ignored&quot;</a>
<a name="423"><span class="lineNum">     423 </span>            :             );</a>
<a name="424"><span class="lineNum">     424 </span>            :         }</a>
<a name="425"><span class="lineNum">     425 </span>            :     }</a>
<a name="426"><span class="lineNum">     426 </span>            : </a>
<a name="427"><span class="lineNum">     427 </span>            :     if (available_devices.empty()) {</a>
<a name="428"><span class="lineNum">     428 </span>            :         this-&gt;error(</a>
<a name="429"><span class="lineNum">     429 </span>            :             &quot;failed to find a valid device for the model at '&quot; + model_path + &quot;': &quot;</a>
<a name="430"><span class="lineNum">     430 </span>            :             &quot;the model supports &quot; + torch::str(this-&gt;capabilities_-&gt;supported_devices) +</a>
<a name="431"><span class="lineNum">     431 </span>            :             &quot;, none of these where available&quot;</a>
<a name="432"><span class="lineNum">     432 </span>            :         );</a>
<a name="433"><span class="lineNum">     433 </span>            :     }</a>
<a name="434"><span class="lineNum">     434 </span>            : </a>
<a name="435"><span class="lineNum">     435 </span>            :     std::string requested_device;</a>
<a name="436"><span class="lineNum">     436 </span>            :     this-&gt;parse(&quot;DEVICE&quot;, requested_device);</a>
<a name="437"><span class="lineNum">     437 </span>            :     if (requested_device.empty()) {</a>
<a name="438"><span class="lineNum">     438 </span>            :         // no user request, pick the device the model prefers</a>
<a name="439"><span class="lineNum">     439 </span>            :         this-&gt;device_ = available_devices[0];</a>
<a name="440"><span class="lineNum">     440 </span>            :     } else {</a>
<a name="441"><span class="lineNum">     441 </span>            :         bool found_requested_device = false;</a>
<a name="442"><span class="lineNum">     442 </span>            :         for (const auto&amp; device: available_devices) {</a>
<a name="443"><span class="lineNum">     443 </span>            :             if (device.is_cpu() &amp;&amp; requested_device == &quot;cpu&quot;) {</a>
<a name="444"><span class="lineNum">     444 </span>            :                 this-&gt;device_ = device;</a>
<a name="445"><span class="lineNum">     445 </span>            :                 found_requested_device = true;</a>
<a name="446"><span class="lineNum">     446 </span>            :                 break;</a>
<a name="447"><span class="lineNum">     447 </span>            :             } else if (device.is_cuda() &amp;&amp; requested_device == &quot;cuda&quot;) {</a>
<a name="448"><span class="lineNum">     448 </span>            :                 this-&gt;device_ = device;</a>
<a name="449"><span class="lineNum">     449 </span>            :                 found_requested_device = true;</a>
<a name="450"><span class="lineNum">     450 </span>            :                 break;</a>
<a name="451"><span class="lineNum">     451 </span>            :             } else if (device.is_mps() &amp;&amp; requested_device == &quot;mps&quot;) {</a>
<a name="452"><span class="lineNum">     452 </span>            :                 this-&gt;device_ = device;</a>
<a name="453"><span class="lineNum">     453 </span>            :                 found_requested_device = true;</a>
<a name="454"><span class="lineNum">     454 </span>            :                 break;</a>
<a name="455"><span class="lineNum">     455 </span>            :             }</a>
<a name="456"><span class="lineNum">     456 </span>            :         }</a>
<a name="457"><span class="lineNum">     457 </span>            : </a>
<a name="458"><span class="lineNum">     458 </span>            :         if (!found_requested_device) {</a>
<a name="459"><span class="lineNum">     459 </span>            :             this-&gt;error(</a>
<a name="460"><span class="lineNum">     460 </span>            :                 &quot;failed to find requested device (&quot; + requested_device + &quot;): it is either &quot;</a>
<a name="461"><span class="lineNum">     461 </span>            :                 &quot;not supported by this model or not available on this machine&quot;</a>
<a name="462"><span class="lineNum">     462 </span>            :             );</a>
<a name="463"><span class="lineNum">     463 </span>            :         }</a>
<a name="464"><span class="lineNum">     464 </span>            :     }</a>
<a name="465"><span class="lineNum">     465 </span>            : </a>
<a name="466"><span class="lineNum">     466 </span>            :     this-&gt;model_.to(this-&gt;device_);</a>
<a name="467"><span class="lineNum">     467 </span>            :     this-&gt;atomic_types_ = this-&gt;atomic_types_.to(this-&gt;device_);</a>
<a name="468"><span class="lineNum">     468 </span>            : </a>
<a name="469"><span class="lineNum">     469 </span>            :     log.printf(</a>
<a name="470"><span class="lineNum">     470 </span>            :         &quot;  running model on %s device with %s data\n&quot;,</a>
<a name="471"><span class="lineNum">     471 </span>            :         this-&gt;device_.str().c_str(),</a>
<a name="472"><span class="lineNum">     472 </span>            :         this-&gt;capabilities_-&gt;dtype().c_str()</a>
<a name="473"><span class="lineNum">     473 </span>            :     );</a>
<a name="474"><span class="lineNum">     474 </span>            : </a>
<a name="475"><span class="lineNum">     475 </span>            :     if (this-&gt;capabilities_-&gt;dtype() == &quot;float64&quot;) {</a>
<a name="476"><span class="lineNum">     476 </span>            :         this-&gt;dtype_ = torch::kFloat64;</a>
<a name="477"><span class="lineNum">     477 </span>            :     } else if (this-&gt;capabilities_-&gt;dtype() == &quot;float32&quot;) {</a>
<a name="478"><span class="lineNum">     478 </span>            :         this-&gt;dtype_ = torch::kFloat32;</a>
<a name="479"><span class="lineNum">     479 </span>            :     } else {</a>
<a name="480"><span class="lineNum">     480 </span>            :         this-&gt;error(</a>
<a name="481"><span class="lineNum">     481 </span>            :             &quot;the model requested an unsupported dtype '&quot; + this-&gt;capabilities_-&gt;dtype() + &quot;'&quot;</a>
<a name="482"><span class="lineNum">     482 </span>            :         );</a>
<a name="483"><span class="lineNum">     483 </span>            :     }</a>
<a name="484"><span class="lineNum">     484 </span>            : </a>
<a name="485"><span class="lineNum">     485 </span>            :     auto tensor_options = torch::TensorOptions().dtype(this-&gt;dtype_).device(this-&gt;device_);</a>
<a name="486"><span class="lineNum">     486 </span>            :     this-&gt;strain_ = torch::eye(3, tensor_options.requires_grad(true));</a>
<a name="487"><span class="lineNum">     487 </span>            : </a>
<a name="488"><span class="lineNum">     488 </span>            :     // determine how many properties there will be in the output by running the</a>
<a name="489"><span class="lineNum">     489 </span>            :     // model once on a dummy system</a>
<a name="490"><span class="lineNum">     490 </span>            :     auto dummy_system = torch::make_intrusive&lt;metatensor_torch::SystemHolder&gt;(</a>
<a name="491"><span class="lineNum">     491 </span>            :         /*types = */ torch::zeros({0}, tensor_options.dtype(torch::kInt32)),</a>
<a name="492"><span class="lineNum">     492 </span>            :         /*positions = */ torch::zeros({0, 3}, tensor_options),</a>
<a name="493"><span class="lineNum">     493 </span>            :         /*cell = */ torch::zeros({3, 3}, tensor_options)</a>
<a name="494"><span class="lineNum">     494 </span>            :     );</a>
<a name="495"><span class="lineNum">     495 </span>            : </a>
<a name="496"><span class="lineNum">     496 </span>            :     log.printf(&quot;  the following neighbor lists have been requested:\n&quot;);</a>
<a name="497"><span class="lineNum">     497 </span>            :     auto length_unit = this-&gt;getUnits().getLengthString();</a>
<a name="498"><span class="lineNum">     498 </span>            :     auto model_length_unit = this-&gt;capabilities_-&gt;length_unit();</a>
<a name="499"><span class="lineNum">     499 </span>            :     for (auto request: this-&gt;nl_requests_) {</a>
<a name="500"><span class="lineNum">     500 </span>            :         log.printf(&quot;    - %s list, %g %s cutoff (requested %g %s)\n&quot;,</a>
<a name="501"><span class="lineNum">     501 </span>            :             request-&gt;full_list() ? &quot;full&quot; : &quot;half&quot;,</a>
<a name="502"><span class="lineNum">     502 </span>            :             request-&gt;engine_cutoff(length_unit),</a>
<a name="503"><span class="lineNum">     503 </span>            :             length_unit.c_str(),</a>
<a name="504"><span class="lineNum">     504 </span>            :             request-&gt;cutoff(),</a>
<a name="505"><span class="lineNum">     505 </span>            :             model_length_unit.c_str()</a>
<a name="506"><span class="lineNum">     506 </span>            :         );</a>
<a name="507"><span class="lineNum">     507 </span>            : </a>
<a name="508"><span class="lineNum">     508 </span>            :         auto neighbors = this-&gt;computeNeighbors(request, {PLMD::Vector(0, 0, 0)}, PLMD::Tensor(0, 0, 0, 0, 0, 0, 0, 0, 0));</a>
<a name="509"><span class="lineNum">     509 </span>            :         metatensor_torch::register_autograd_neighbors(dummy_system, neighbors, this-&gt;check_consistency_);</a>
<a name="510"><span class="lineNum">     510 </span>            :         dummy_system-&gt;add_neighbor_list(request, neighbors);</a>
<a name="511"><span class="lineNum">     511 </span>            :     }</a>
<a name="512"><span class="lineNum">     512 </span>            : </a>
<a name="513"><span class="lineNum">     513 </span>            :     this-&gt;n_properties_ = static_cast&lt;unsigned&gt;(</a>
<a name="514"><span class="lineNum">     514 </span>            :         this-&gt;executeModel(dummy_system)-&gt;properties()-&gt;count()</a>
<a name="515"><span class="lineNum">     515 </span>            :     );</a>
<a name="516"><span class="lineNum">     516 </span>            : </a>
<a name="517"><span class="lineNum">     517 </span>            :     // parse and handle atom sub-selection. This is done AFTER determining the</a>
<a name="518"><span class="lineNum">     518 </span>            :     // output size, since the selection might not be valid for the dummy system</a>
<a name="519"><span class="lineNum">     519 </span>            :     std::vector&lt;int32_t&gt; selected_atoms;</a>
<a name="520"><span class="lineNum">     520 </span>            :     this-&gt;parseVector(&quot;SELECTED_ATOMS&quot;, selected_atoms);</a>
<a name="521"><span class="lineNum">     521 </span>            :     if (!selected_atoms.empty()) {</a>
<a name="522"><span class="lineNum">     522 </span>            :         auto selection_value = torch::zeros(</a>
<a name="523"><span class="lineNum">     523 </span>            :             {static_cast&lt;int64_t&gt;(selected_atoms.size()), 2},</a>
<a name="524"><span class="lineNum">     524 </span>            :             torch::TensorOptions().dtype(torch::kInt32).device(this-&gt;device_)</a>
<a name="525"><span class="lineNum">     525 </span>            :         );</a>
<a name="526"><span class="lineNum">     526 </span>            : </a>
<a name="527"><span class="lineNum">     527 </span>            :         for (unsigned i=0; i&lt;selected_atoms.size(); i++) {</a>
<a name="528"><span class="lineNum">     528 </span>            :             auto n_atoms = static_cast&lt;int32_t&gt;(this-&gt;atomic_types_.size(0));</a>
<a name="529"><span class="lineNum">     529 </span>            :             if (selected_atoms[i] &lt;= 0 || selected_atoms[i] &gt; n_atoms) {</a>
<a name="530"><span class="lineNum">     530 </span>            :                 this-&gt;error(</a>
<a name="531"><span class="lineNum">     531 </span>            :                     &quot;Values in metatensor's SELECTED_ATOMS should be between 1 &quot;</a>
<a name="532"><span class="lineNum">     532 </span>            :                     &quot;and the number of atoms (&quot; + std::to_string(n_atoms) + &quot;), &quot;</a>
<a name="533"><span class="lineNum">     533 </span>            :                     &quot;got &quot; + std::to_string(selected_atoms[i]));</a>
<a name="534"><span class="lineNum">     534 </span>            :             }</a>
<a name="535"><span class="lineNum">     535 </span>            :             // PLUMED input uses 1-based indexes, but metatensor wants 0-based</a>
<a name="536"><span class="lineNum">     536 </span>            :             selection_value[i][1] = selected_atoms[i] - 1;</a>
<a name="537"><span class="lineNum">     537 </span>            :         }</a>
<a name="538"><span class="lineNum">     538 </span>            : </a>
<a name="539"><span class="lineNum">     539 </span>            :         evaluations_options_-&gt;set_selected_atoms(</a>
<a name="540"><span class="lineNum">     540 </span>            :             torch::make_intrusive&lt;metatensor_torch::LabelsHolder&gt;(</a>
<a name="541"><span class="lineNum">     541 </span>            :                 std::vector&lt;std::string&gt;{&quot;system&quot;, &quot;atom&quot;}, selection_value</a>
<a name="542"><span class="lineNum">     542 </span>            :             )</a>
<a name="543"><span class="lineNum">     543 </span>            :         );</a>
<a name="544"><span class="lineNum">     544 </span>            :     }</a>
<a name="545"><span class="lineNum">     545 </span>            : </a>
<a name="546"><span class="lineNum">     546 </span>            :     // Now that we now both n_samples and n_properties, we can setup the</a>
<a name="547"><span class="lineNum">     547 </span>            :     // PLUMED-side storage for the computed CV</a>
<a name="548"><span class="lineNum">     548 </span>            :     if (output-&gt;per_atom) {</a>
<a name="549"><span class="lineNum">     549 </span>            :         if (selected_atoms.empty()) {</a>
<a name="550"><span class="lineNum">     550 </span>            :             this-&gt;n_samples_ = static_cast&lt;unsigned&gt;(this-&gt;atomic_types_.size(0));</a>
<a name="551"><span class="lineNum">     551 </span>            :         } else {</a>
<a name="552"><span class="lineNum">     552 </span>            :             this-&gt;n_samples_ = static_cast&lt;unsigned&gt;(selected_atoms.size());</a>
<a name="553"><span class="lineNum">     553 </span>            :         }</a>
<a name="554"><span class="lineNum">     554 </span>            :     } else {</a>
<a name="555"><span class="lineNum">     555 </span>            :         this-&gt;n_samples_ = 1;</a>
<a name="556"><span class="lineNum">     556 </span>            :     }</a>
<a name="557"><span class="lineNum">     557 </span>            : </a>
<a name="558"><span class="lineNum">     558 </span>            :     if (n_samples_ == 1 &amp;&amp; n_properties_ == 1) {</a>
<a name="559"><span class="lineNum">     559 </span>            :         log.printf(&quot;  the output of this model is a scalar\n&quot;);</a>
<a name="560"><span class="lineNum">     560 </span>            : </a>
<a name="561"><span class="lineNum">     561 </span>            :         this-&gt;addValue();</a>
<a name="562"><span class="lineNum">     562 </span>            :     } else if (n_samples_ == 1) {</a>
<a name="563"><span class="lineNum">     563 </span>            :         log.printf(&quot;  the output of this model is 1x%d vector\n&quot;, n_properties_);</a>
<a name="564"><span class="lineNum">     564 </span>            : </a>
<a name="565"><span class="lineNum">     565 </span>            :         this-&gt;addValue({this-&gt;n_properties_});</a>
<a name="566"><span class="lineNum">     566 </span>            :         this-&gt;getPntrToComponent(0)-&gt;buildDataStore();</a>
<a name="567"><span class="lineNum">     567 </span>            :     } else if (n_properties_ == 1) {</a>
<a name="568"><span class="lineNum">     568 </span>            :         log.printf(&quot;  the output of this model is %dx1 vector\n&quot;, n_samples_);</a>
<a name="569"><span class="lineNum">     569 </span>            : </a>
<a name="570"><span class="lineNum">     570 </span>            :         this-&gt;addValue({this-&gt;n_samples_});</a>
<a name="571"><span class="lineNum">     571 </span>            :         this-&gt;getPntrToComponent(0)-&gt;buildDataStore();</a>
<a name="572"><span class="lineNum">     572 </span>            :     } else {</a>
<a name="573"><span class="lineNum">     573 </span>            :         log.printf(&quot;  the output of this model is a %dx%d matrix\n&quot;, n_samples_, n_properties_);</a>
<a name="574"><span class="lineNum">     574 </span>            : </a>
<a name="575"><span class="lineNum">     575 </span>            :         this-&gt;addValue({this-&gt;n_samples_, this-&gt;n_properties_});</a>
<a name="576"><span class="lineNum">     576 </span>            :         this-&gt;getPntrToComponent(0)-&gt;buildDataStore();</a>
<a name="577"><span class="lineNum">     577 </span>            :         this-&gt;getPntrToComponent(0)-&gt;reshapeMatrixStore(n_properties_);</a>
<a name="578"><span class="lineNum">     578 </span>            :     }</a>
<a name="579"><span class="lineNum">     579 </span>            : </a>
<a name="580"><span class="lineNum">     580 </span>            :     this-&gt;setNotPeriodic();</a>
<a name="581"><span class="lineNum">     581 </span>            : }</a>
<a name="582"><span class="lineNum">     582 </span>            : </a>
<a name="583"><span class="lineNum">     583 </span>            : unsigned MetatensorPlumedAction::getNumberOfDerivatives() {</a>
<a name="584"><span class="lineNum">     584 </span>            :     // gradients w.r.t. positions (3 x N values) + gradients w.r.t. strain (9 values)</a>
<a name="585"><span class="lineNum">     585 </span>            :     return 3 * this-&gt;getNumberOfAtoms() + 9;</a>
<a name="586"><span class="lineNum">     586 </span>            : }</a>
<a name="587"><span class="lineNum">     587 </span>            : </a>
<a name="588"><span class="lineNum">     588 </span>            : </a>
<a name="589"><span class="lineNum">     589 </span>            : void MetatensorPlumedAction::createSystem() {</a>
<a name="590"><span class="lineNum">     590 </span>            :     if (this-&gt;getTotAtoms() != static_cast&lt;unsigned&gt;(this-&gt;atomic_types_.size(0))) {</a>
<a name="591"><span class="lineNum">     591 </span>            :         std::ostringstream oss;</a>
<a name="592"><span class="lineNum">     592 </span>            :         oss &lt;&lt; &quot;METATENSOR action needs to know about all atoms in the system. &quot;;</a>
<a name="593"><span class="lineNum">     593 </span>            :         oss &lt;&lt; &quot;There are &quot; &lt;&lt; this-&gt;getTotAtoms() &lt;&lt; &quot; atoms overall, &quot;;</a>
<a name="594"><span class="lineNum">     594 </span>            :         oss &lt;&lt; &quot;but we only have atomic types for &quot; &lt;&lt; this-&gt;atomic_types_.size(0) &lt;&lt; &quot; of them.&quot;;</a>
<a name="595"><span class="lineNum">     595 </span>            :         plumed_merror(oss.str());</a>
<a name="596"><span class="lineNum">     596 </span>            :     }</a>
<a name="597"><span class="lineNum">     597 </span>            : </a>
<a name="598"><span class="lineNum">     598 </span>            :     // this-&gt;getTotAtoms()</a>
<a name="599"><span class="lineNum">     599 </span>            : </a>
<a name="600"><span class="lineNum">     600 </span>            :     const auto&amp; cell = this-&gt;getPbc().getBox();</a>
<a name="601"><span class="lineNum">     601 </span>            : </a>
<a name="602"><span class="lineNum">     602 </span>            :     auto cpu_f64_tensor = torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU);</a>
<a name="603"><span class="lineNum">     603 </span>            :     auto torch_cell = torch::zeros({3, 3}, cpu_f64_tensor);</a>
<a name="604"><span class="lineNum">     604 </span>            : </a>
<a name="605"><span class="lineNum">     605 </span>            :     torch_cell[0][0] = cell(0, 0);</a>
<a name="606"><span class="lineNum">     606 </span>            :     torch_cell[0][1] = cell(0, 1);</a>
<a name="607"><span class="lineNum">     607 </span>            :     torch_cell[0][2] = cell(0, 2);</a>
<a name="608"><span class="lineNum">     608 </span>            : </a>
<a name="609"><span class="lineNum">     609 </span>            :     torch_cell[1][0] = cell(1, 0);</a>
<a name="610"><span class="lineNum">     610 </span>            :     torch_cell[1][1] = cell(1, 1);</a>
<a name="611"><span class="lineNum">     611 </span>            :     torch_cell[1][2] = cell(1, 2);</a>
<a name="612"><span class="lineNum">     612 </span>            : </a>
<a name="613"><span class="lineNum">     613 </span>            :     torch_cell[2][0] = cell(2, 0);</a>
<a name="614"><span class="lineNum">     614 </span>            :     torch_cell[2][1] = cell(2, 1);</a>
<a name="615"><span class="lineNum">     615 </span>            :     torch_cell[2][2] = cell(2, 2);</a>
<a name="616"><span class="lineNum">     616 </span>            : </a>
<a name="617"><span class="lineNum">     617 </span>            :     const auto&amp; positions = this-&gt;getPositions();</a>
<a name="618"><span class="lineNum">     618 </span>            : </a>
<a name="619"><span class="lineNum">     619 </span>            :     auto torch_positions = torch::from_blob(</a>
<a name="620"><span class="lineNum">     620 </span>            :         const_cast&lt;PLMD::Vector*&gt;(positions.data()),</a>
<a name="621"><span class="lineNum">     621 </span>            :         {static_cast&lt;int64_t&gt;(positions.size()), 3},</a>
<a name="622"><span class="lineNum">     622 </span>            :         cpu_f64_tensor</a>
<a name="623"><span class="lineNum">     623 </span>            :     );</a>
<a name="624"><span class="lineNum">     624 </span>            : </a>
<a name="625"><span class="lineNum">     625 </span>            :     torch_positions = torch_positions.to(this-&gt;dtype_).to(this-&gt;device_);</a>
<a name="626"><span class="lineNum">     626 </span>            :     torch_cell = torch_cell.to(this-&gt;dtype_).to(this-&gt;device_);</a>
<a name="627"><span class="lineNum">     627 </span>            : </a>
<a name="628"><span class="lineNum">     628 </span>            :     // setup torch's automatic gradient tracking</a>
<a name="629"><span class="lineNum">     629 </span>            :     if (!this-&gt;doNotCalculateDerivatives()) {</a>
<a name="630"><span class="lineNum">     630 </span>            :         torch_positions.requires_grad_(true);</a>
<a name="631"><span class="lineNum">     631 </span>            : </a>
<a name="632"><span class="lineNum">     632 </span>            :         // pretend to scale positions/cell by the strain so that it enters the</a>
<a name="633"><span class="lineNum">     633 </span>            :         // computational graph.</a>
<a name="634"><span class="lineNum">     634 </span>            :         torch_positions = torch_positions.matmul(this-&gt;strain_);</a>
<a name="635"><span class="lineNum">     635 </span>            :         torch_positions.retain_grad();</a>
<a name="636"><span class="lineNum">     636 </span>            : </a>
<a name="637"><span class="lineNum">     637 </span>            :         torch_cell = torch_cell.matmul(this-&gt;strain_);</a>
<a name="638"><span class="lineNum">     638 </span>            :     }</a>
<a name="639"><span class="lineNum">     639 </span>            : </a>
<a name="640"><span class="lineNum">     640 </span>            :     this-&gt;system_ = torch::make_intrusive&lt;metatensor_torch::SystemHolder&gt;(</a>
<a name="641"><span class="lineNum">     641 </span>            :         this-&gt;atomic_types_,</a>
<a name="642"><span class="lineNum">     642 </span>            :         torch_positions,</a>
<a name="643"><span class="lineNum">     643 </span>            :         torch_cell</a>
<a name="644"><span class="lineNum">     644 </span>            :     );</a>
<a name="645"><span class="lineNum">     645 </span>            : </a>
<a name="646"><span class="lineNum">     646 </span>            :     // compute the neighbors list requested by the model, and register them with</a>
<a name="647"><span class="lineNum">     647 </span>            :     // the system</a>
<a name="648"><span class="lineNum">     648 </span>            :     for (auto request: this-&gt;nl_requests_) {</a>
<a name="649"><span class="lineNum">     649 </span>            :         auto neighbors = this-&gt;computeNeighbors(request, positions, cell);</a>
<a name="650"><span class="lineNum">     650 </span>            :         metatensor_torch::register_autograd_neighbors(this-&gt;system_, neighbors, this-&gt;check_consistency_);</a>
<a name="651"><span class="lineNum">     651 </span>            :         this-&gt;system_-&gt;add_neighbor_list(request, neighbors);</a>
<a name="652"><span class="lineNum">     652 </span>            :     }</a>
<a name="653"><span class="lineNum">     653 </span>            : }</a>
<a name="654"><span class="lineNum">     654 </span>            : </a>
<a name="655"><span class="lineNum">     655 </span>            : </a>
<a name="656"><span class="lineNum">     656 </span>            : metatensor_torch::TorchTensorBlock MetatensorPlumedAction::computeNeighbors(</a>
<a name="657"><span class="lineNum">     657 </span>            :     metatensor_torch::NeighborListOptions request,</a>
<a name="658"><span class="lineNum">     658 </span>            :     const std::vector&lt;PLMD::Vector&gt;&amp; positions,</a>
<a name="659"><span class="lineNum">     659 </span>            :     const PLMD::Tensor&amp; cell</a>
<a name="660"><span class="lineNum">     660 </span>            : ) {</a>
<a name="661"><span class="lineNum">     661 </span>            :     auto labels_options = torch::TensorOptions().dtype(torch::kInt32).device(this-&gt;device_);</a>
<a name="662"><span class="lineNum">     662 </span>            :     auto neighbor_component = torch::make_intrusive&lt;metatensor_torch::LabelsHolder&gt;(</a>
<a name="663"><span class="lineNum">     663 </span>            :         &quot;xyz&quot;,</a>
<a name="664"><span class="lineNum">     664 </span>            :         torch::tensor({0, 1, 2}, labels_options).reshape({3, 1})</a>
<a name="665"><span class="lineNum">     665 </span>            :     );</a>
<a name="666"><span class="lineNum">     666 </span>            :     auto neighbor_properties = torch::make_intrusive&lt;metatensor_torch::LabelsHolder&gt;(</a>
<a name="667"><span class="lineNum">     667 </span>            :         &quot;distance&quot;, torch::zeros({1, 1}, labels_options)</a>
<a name="668"><span class="lineNum">     668 </span>            :     );</a>
<a name="669"><span class="lineNum">     669 </span>            : </a>
<a name="670"><span class="lineNum">     670 </span>            :     auto cutoff = request-&gt;engine_cutoff(this-&gt;getUnits().getLengthString());</a>
<a name="671"><span class="lineNum">     671 </span>            : </a>
<a name="672"><span class="lineNum">     672 </span>            :     auto non_periodic = (</a>
<a name="673"><span class="lineNum">     673 </span>            :         cell(0, 0) == 0.0 &amp;&amp; cell(0, 1) == 0.0 &amp;&amp; cell(0, 2) == 0.0 &amp;&amp;</a>
<a name="674"><span class="lineNum">     674 </span>            :         cell(1, 0) == 0.0 &amp;&amp; cell(1, 1) == 0.0 &amp;&amp; cell(1, 2) == 0.0 &amp;&amp;</a>
<a name="675"><span class="lineNum">     675 </span>            :         cell(2, 0) == 0.0 &amp;&amp; cell(2, 2) == 0.0 &amp;&amp; cell(2, 2) == 0.0</a>
<a name="676"><span class="lineNum">     676 </span>            :     );</a>
<a name="677"><span class="lineNum">     677 </span>            : </a>
<a name="678"><span class="lineNum">     678 </span>            :     // use https://github.com/Luthaf/vesin to compute the requested neighbor</a>
<a name="679"><span class="lineNum">     679 </span>            :     // lists since we can not get these from PLUMED</a>
<a name="680"><span class="lineNum">     680 </span>            :     vesin::VesinOptions options;</a>
<a name="681"><span class="lineNum">     681 </span>            :     options.cutoff = cutoff;</a>
<a name="682"><span class="lineNum">     682 </span>            :     options.full = request-&gt;full_list();</a>
<a name="683"><span class="lineNum">     683 </span>            :     options.return_shifts = true;</a>
<a name="684"><span class="lineNum">     684 </span>            :     options.return_distances = false;</a>
<a name="685"><span class="lineNum">     685 </span>            :     options.return_vectors = true;</a>
<a name="686"><span class="lineNum">     686 </span>            : </a>
<a name="687"><span class="lineNum">     687 </span>            :     vesin::VesinNeighborList* vesin_neighbor_list = new vesin::VesinNeighborList();</a>
<a name="688"><span class="lineNum">     688 </span>            :     memset(vesin_neighbor_list, 0, sizeof(vesin::VesinNeighborList));</a>
<a name="689"><span class="lineNum">     689 </span>            : </a>
<a name="690"><span class="lineNum">     690 </span>            :     const char* error_message = NULL;</a>
<a name="691"><span class="lineNum">     691 </span>            :     int status = vesin_neighbors(</a>
<a name="692"><span class="lineNum">     692 </span>            :         reinterpret_cast&lt;const double (*)[3]&gt;(positions.data()),</a>
<a name="693"><span class="lineNum">     693 </span>            :         positions.size(),</a>
<a name="694"><span class="lineNum">     694 </span>            :         reinterpret_cast&lt;const double (*)[3]&gt;(&amp;cell(0, 0)),</a>
<a name="695"><span class="lineNum">     695 </span>            :         !non_periodic,</a>
<a name="696"><span class="lineNum">     696 </span>            :         vesin::VesinCPU,</a>
<a name="697"><span class="lineNum">     697 </span>            :         options,</a>
<a name="698"><span class="lineNum">     698 </span>            :         vesin_neighbor_list,</a>
<a name="699"><span class="lineNum">     699 </span>            :         &amp;error_message</a>
<a name="700"><span class="lineNum">     700 </span>            :     );</a>
<a name="701"><span class="lineNum">     701 </span>            : </a>
<a name="702"><span class="lineNum">     702 </span>            :     if (status != EXIT_SUCCESS) {</a>
<a name="703"><span class="lineNum">     703 </span>            :         plumed_merror(</a>
<a name="704"><span class="lineNum">     704 </span>            :             &quot;failed to compute neighbor list (cutoff=&quot; + std::to_string(cutoff) +</a>
<a name="705"><span class="lineNum">     705 </span>            :             &quot;, full=&quot; + (request-&gt;full_list() ? &quot;true&quot; : &quot;false&quot;) + &quot;): &quot; + error_message</a>
<a name="706"><span class="lineNum">     706 </span>            :         );</a>
<a name="707"><span class="lineNum">     707 </span>            :     }</a>
<a name="708"><span class="lineNum">     708 </span>            : </a>
<a name="709"><span class="lineNum">     709 </span>            :     // transform from vesin to metatensor format</a>
<a name="710"><span class="lineNum">     710 </span>            :     auto n_pairs = static_cast&lt;int64_t&gt;(vesin_neighbor_list-&gt;length);</a>
<a name="711"><span class="lineNum">     711 </span>            : </a>
<a name="712"><span class="lineNum">     712 </span>            :     auto pair_vectors = torch::from_blob(</a>
<a name="713"><span class="lineNum">     713 </span>            :         vesin_neighbor_list-&gt;vectors,</a>
<a name="714"><span class="lineNum">     714 </span>            :         {n_pairs, 3, 1},</a>
<a name="715"><span class="lineNum">     715 </span>            :         /*deleter*/ [=](void*) {</a>
<a name="716"><span class="lineNum">     716 </span>            :             vesin_free(vesin_neighbor_list);</a>
<a name="717"><span class="lineNum">     717 </span>            :             delete vesin_neighbor_list;</a>
<a name="718"><span class="lineNum">     718 </span>            :         },</a>
<a name="719"><span class="lineNum">     719 </span>            :         torch::TensorOptions().dtype(torch::kFloat64).device(torch::kCPU)</a>
<a name="720"><span class="lineNum">     720 </span>            :     );</a>
<a name="721"><span class="lineNum">     721 </span>            : </a>
<a name="722"><span class="lineNum">     722 </span>            :     auto pair_samples_values = torch::zeros({n_pairs, 5}, labels_options.device(torch::kCPU));</a>
<a name="723"><span class="lineNum">     723 </span>            :     for (unsigned i=0; i&lt;n_pairs; i++) {</a>
<a name="724"><span class="lineNum">     724 </span>            :         pair_samples_values[i][0] = static_cast&lt;int32_t&gt;(vesin_neighbor_list-&gt;pairs[i][0]);</a>
<a name="725"><span class="lineNum">     725 </span>            :         pair_samples_values[i][1] = static_cast&lt;int32_t&gt;(vesin_neighbor_list-&gt;pairs[i][1]);</a>
<a name="726"><span class="lineNum">     726 </span>            :         pair_samples_values[i][2] = vesin_neighbor_list-&gt;shifts[i][0];</a>
<a name="727"><span class="lineNum">     727 </span>            :         pair_samples_values[i][3] = vesin_neighbor_list-&gt;shifts[i][1];</a>
<a name="728"><span class="lineNum">     728 </span>            :         pair_samples_values[i][4] = vesin_neighbor_list-&gt;shifts[i][2];</a>
<a name="729"><span class="lineNum">     729 </span>            :     }</a>
<a name="730"><span class="lineNum">     730 </span>            : </a>
<a name="731"><span class="lineNum">     731 </span>            :     auto neighbor_samples = torch::make_intrusive&lt;metatensor_torch::LabelsHolder&gt;(</a>
<a name="732"><span class="lineNum">     732 </span>            :         std::vector&lt;std::string&gt;{&quot;first_atom&quot;, &quot;second_atom&quot;, &quot;cell_shift_a&quot;, &quot;cell_shift_b&quot;, &quot;cell_shift_c&quot;},</a>
<a name="733"><span class="lineNum">     733 </span>            :         pair_samples_values.to(this-&gt;device_)</a>
<a name="734"><span class="lineNum">     734 </span>            :     );</a>
<a name="735"><span class="lineNum">     735 </span>            : </a>
<a name="736"><span class="lineNum">     736 </span>            :     auto neighbors = torch::make_intrusive&lt;metatensor_torch::TensorBlockHolder&gt;(</a>
<a name="737"><span class="lineNum">     737 </span>            :         pair_vectors.to(this-&gt;dtype_).to(this-&gt;device_),</a>
<a name="738"><span class="lineNum">     738 </span>            :         neighbor_samples,</a>
<a name="739"><span class="lineNum">     739 </span>            :         std::vector&lt;metatensor_torch::TorchLabels&gt;{neighbor_component},</a>
<a name="740"><span class="lineNum">     740 </span>            :         neighbor_properties</a>
<a name="741"><span class="lineNum">     741 </span>            :     );</a>
<a name="742"><span class="lineNum">     742 </span>            : </a>
<a name="743"><span class="lineNum">     743 </span>            :     return neighbors;</a>
<a name="744"><span class="lineNum">     744 </span>            : }</a>
<a name="745"><span class="lineNum">     745 </span>            : </a>
<a name="746"><span class="lineNum">     746 </span>            : metatensor_torch::TorchTensorBlock MetatensorPlumedAction::executeModel(metatensor_torch::System system) {</a>
<a name="747"><span class="lineNum">     747 </span>            :     try {</a>
<a name="748"><span class="lineNum">     748 </span>            :         auto ivalue_output = this-&gt;model_.forward({</a>
<a name="749"><span class="lineNum">     749 </span>            :             std::vector&lt;metatensor_torch::System&gt;{system},</a>
<a name="750"><span class="lineNum">     750 </span>            :             evaluations_options_,</a>
<a name="751"><span class="lineNum">     751 </span>            :             this-&gt;check_consistency_,</a>
<a name="752"><span class="lineNum">     752 </span>            :         });</a>
<a name="753"><span class="lineNum">     753 </span>            : </a>
<a name="754"><span class="lineNum">     754 </span>            :         auto dict_output = ivalue_output.toGenericDict();</a>
<a name="755"><span class="lineNum">     755 </span>            :         auto cv = dict_output.at(this-&gt;model_output_);</a>
<a name="756"><span class="lineNum">     756 </span>            :         this-&gt;output_ = cv.toCustomClass&lt;metatensor_torch::TensorMapHolder&gt;();</a>
<a name="757"><span class="lineNum">     757 </span>            :     } catch (const std::exception&amp; e) {</a>
<a name="758"><span class="lineNum">     758 </span>            :         plumed_merror(&quot;failed to evaluate the model: &quot; + std::string(e.what()));</a>
<a name="759"><span class="lineNum">     759 </span>            :     }</a>
<a name="760"><span class="lineNum">     760 </span>            : </a>
<a name="761"><span class="lineNum">     761 </span>            :     plumed_massert(this-&gt;output_-&gt;keys()-&gt;count() == 1, &quot;output should have a single block&quot;);</a>
<a name="762"><span class="lineNum">     762 </span>            :     auto block = metatensor_torch::TensorMapHolder::block_by_id(this-&gt;output_, 0);</a>
<a name="763"><span class="lineNum">     763 </span>            :     plumed_massert(block-&gt;components().empty(), &quot;components are not yet supported in the output&quot;);</a>
<a name="764"><span class="lineNum">     764 </span>            : </a>
<a name="765"><span class="lineNum">     765 </span>            :     return block;</a>
<a name="766"><span class="lineNum">     766 </span>            : }</a>
<a name="767"><span class="lineNum">     767 </span>            : </a>
<a name="768"><span class="lineNum">     768 </span>            : </a>
<a name="769"><span class="lineNum">     769 </span>            : void MetatensorPlumedAction::calculate() {</a>
<a name="770"><span class="lineNum">     770 </span>            :     this-&gt;createSystem();</a>
<a name="771"><span class="lineNum">     771 </span>            : </a>
<a name="772"><span class="lineNum">     772 </span>            :     auto block = this-&gt;executeModel(this-&gt;system_);</a>
<a name="773"><span class="lineNum">     773 </span>            :     auto torch_values = block-&gt;values().to(torch::kCPU).to(torch::kFloat64);</a>
<a name="774"><span class="lineNum">     774 </span>            : </a>
<a name="775"><span class="lineNum">     775 </span>            :     if (static_cast&lt;unsigned&gt;(torch_values.size(0)) != this-&gt;n_samples_) {</a>
<a name="776"><span class="lineNum">     776 </span>            :         plumed_merror(</a>
<a name="777"><span class="lineNum">     777 </span>            :             &quot;expected the model to return a TensorBlock with &quot; +</a>
<a name="778"><span class="lineNum">     778 </span>            :             std::to_string(this-&gt;n_samples_) + &quot; samples, got &quot; +</a>
<a name="779"><span class="lineNum">     779 </span>            :             std::to_string(torch_values.size(0)) + &quot; instead&quot;</a>
<a name="780"><span class="lineNum">     780 </span>            :         );</a>
<a name="781"><span class="lineNum">     781 </span>            :     } else if (static_cast&lt;unsigned&gt;(torch_values.size(1)) != this-&gt;n_properties_) {</a>
<a name="782"><span class="lineNum">     782 </span>            :         plumed_merror(</a>
<a name="783"><span class="lineNum">     783 </span>            :             &quot;expected the model to return a TensorBlock with &quot; +</a>
<a name="784"><span class="lineNum">     784 </span>            :             std::to_string(this-&gt;n_properties_) + &quot; properties, got &quot; +</a>
<a name="785"><span class="lineNum">     785 </span>            :             std::to_string(torch_values.size(1)) + &quot; instead&quot;</a>
<a name="786"><span class="lineNum">     786 </span>            :         );</a>
<a name="787"><span class="lineNum">     787 </span>            :     }</a>
<a name="788"><span class="lineNum">     788 </span>            : </a>
<a name="789"><span class="lineNum">     789 </span>            :     Value* value = this-&gt;getPntrToComponent(0);</a>
<a name="790"><span class="lineNum">     790 </span>            :     // reshape the plumed `Value` to hold the data returned by the model</a>
<a name="791"><span class="lineNum">     791 </span>            :     if (n_samples_ == 1) {</a>
<a name="792"><span class="lineNum">     792 </span>            :         if (n_properties_ == 1) {</a>
<a name="793"><span class="lineNum">     793 </span>            :             value-&gt;set(torch_values.item&lt;double&gt;());</a>
<a name="794"><span class="lineNum">     794 </span>            :         } else {</a>
<a name="795"><span class="lineNum">     795 </span>            :             // we have multiple CV describing a single thing (atom or full system)</a>
<a name="796"><span class="lineNum">     796 </span>            :             for (unsigned i=0; i&lt;n_properties_; i++) {</a>
<a name="797"><span class="lineNum">     797 </span>            :                 value-&gt;set(i, torch_values[0][i].item&lt;double&gt;());</a>
<a name="798"><span class="lineNum">     798 </span>            :             }</a>
<a name="799"><span class="lineNum">     799 </span>            :         }</a>
<a name="800"><span class="lineNum">     800 </span>            :     } else {</a>
<a name="801"><span class="lineNum">     801 </span>            :         auto samples = block-&gt;samples();</a>
<a name="802"><span class="lineNum">     802 </span>            :         plumed_assert((samples-&gt;names() == std::vector&lt;std::string&gt;{&quot;system&quot;, &quot;atom&quot;}));</a>
<a name="803"><span class="lineNum">     803 </span>            : </a>
<a name="804"><span class="lineNum">     804 </span>            :         auto samples_values = samples-&gt;values().to(torch::kCPU);</a>
<a name="805"><span class="lineNum">     805 </span>            :         auto selected_atoms = this-&gt;evaluations_options_-&gt;get_selected_atoms();</a>
<a name="806"><span class="lineNum">     806 </span>            : </a>
<a name="807"><span class="lineNum">     807 </span>            :         // handle the possibility that samples are returned in</a>
<a name="808"><span class="lineNum">     808 </span>            :         // a non-sorted order.</a>
<a name="809"><span class="lineNum">     809 </span>            :         auto get_output_location = [&amp;](unsigned i) {</a>
<a name="810"><span class="lineNum">     810 </span>            :             if (selected_atoms.has_value()) {</a>
<a name="811"><span class="lineNum">     811 </span>            :                 // If the users picked some selected atoms, then we store the</a>
<a name="812"><span class="lineNum">     812 </span>            :                 // output in the same order as the selection was given</a>
<a name="813"><span class="lineNum">     813 </span>            :                 auto sample = samples_values.index({static_cast&lt;int64_t&gt;(i), torch::indexing::Slice()});</a>
<a name="814"><span class="lineNum">     814 </span>            :                 auto position = selected_atoms.value()-&gt;position(sample);</a>
<a name="815"><span class="lineNum">     815 </span>            :                 plumed_assert(position.has_value());</a>
<a name="816"><span class="lineNum">     816 </span>            :                 return static_cast&lt;unsigned&gt;(position.value());</a>
<a name="817"><span class="lineNum">     817 </span>            :             } else {</a>
<a name="818"><span class="lineNum">     818 </span>            :                 return static_cast&lt;unsigned&gt;(samples_values[i][1].item&lt;int32_t&gt;());</a>
<a name="819"><span class="lineNum">     819 </span>            :             }</a>
<a name="820"><span class="lineNum">     820 </span>            :         };</a>
<a name="821"><span class="lineNum">     821 </span>            : </a>
<a name="822"><span class="lineNum">     822 </span>            :         if (n_properties_ == 1) {</a>
<a name="823"><span class="lineNum">     823 </span>            :             // we have a single CV describing multiple things (i.e. atoms)</a>
<a name="824"><span class="lineNum">     824 </span>            :             for (unsigned i=0; i&lt;n_samples_; i++) {</a>
<a name="825"><span class="lineNum">     825 </span>            :                 auto output_i = get_output_location(i);</a>
<a name="826"><span class="lineNum">     826 </span>            :                 value-&gt;set(output_i, torch_values[i][0].item&lt;double&gt;());</a>
<a name="827"><span class="lineNum">     827 </span>            :             }</a>
<a name="828"><span class="lineNum">     828 </span>            :         } else {</a>
<a name="829"><span class="lineNum">     829 </span>            :             // the CV is a matrix</a>
<a name="830"><span class="lineNum">     830 </span>            :             for (unsigned i=0; i&lt;n_samples_; i++) {</a>
<a name="831"><span class="lineNum">     831 </span>            :                 auto output_i = get_output_location(i);</a>
<a name="832"><span class="lineNum">     832 </span>            :                 for (unsigned j=0; j&lt;n_properties_; j++) {</a>
<a name="833"><span class="lineNum">     833 </span>            :                     value-&gt;set(output_i * n_properties_ + j, torch_values[i][j].item&lt;double&gt;());</a>
<a name="834"><span class="lineNum">     834 </span>            :                 }</a>
<a name="835"><span class="lineNum">     835 </span>            :             }</a>
<a name="836"><span class="lineNum">     836 </span>            :         }</a>
<a name="837"><span class="lineNum">     837 </span>            :     }</a>
<a name="838"><span class="lineNum">     838 </span>            : }</a>
<a name="839"><span class="lineNum">     839 </span>            : </a>
<a name="840"><span class="lineNum">     840 </span>            : </a>
<a name="841"><span class="lineNum">     841 </span>            : void MetatensorPlumedAction::apply() {</a>
<a name="842"><span class="lineNum">     842 </span>            :     const auto* value = this-&gt;getPntrToComponent(0);</a>
<a name="843"><span class="lineNum">     843 </span>            :     if (!value-&gt;forcesWereAdded()) {</a>
<a name="844"><span class="lineNum">     844 </span>            :         return;</a>
<a name="845"><span class="lineNum">     845 </span>            :     }</a>
<a name="846"><span class="lineNum">     846 </span>            : </a>
<a name="847"><span class="lineNum">     847 </span>            :     auto block = metatensor_torch::TensorMapHolder::block_by_id(this-&gt;output_, 0);</a>
<a name="848"><span class="lineNum">     848 </span>            :     auto torch_values = block-&gt;values().to(torch::kCPU).to(torch::kFloat64);</a>
<a name="849"><span class="lineNum">     849 </span>            : </a>
<a name="850"><span class="lineNum">     850 </span>            :     auto output_grad = torch::zeros_like(torch_values);</a>
<a name="851"><span class="lineNum">     851 </span>            :     if (n_samples_ == 1) {</a>
<a name="852"><span class="lineNum">     852 </span>            :         if (n_properties_ == 1) {</a>
<a name="853"><span class="lineNum">     853 </span>            :             output_grad[0][0] = value-&gt;getForce();</a>
<a name="854"><span class="lineNum">     854 </span>            :         } else {</a>
<a name="855"><span class="lineNum">     855 </span>            :             for (unsigned i=0; i&lt;n_properties_; i++) {</a>
<a name="856"><span class="lineNum">     856 </span>            :                 output_grad[0][i] = value-&gt;getForce(i);</a>
<a name="857"><span class="lineNum">     857 </span>            :             }</a>
<a name="858"><span class="lineNum">     858 </span>            :         }</a>
<a name="859"><span class="lineNum">     859 </span>            :     } else {</a>
<a name="860"><span class="lineNum">     860 </span>            :         auto samples = block-&gt;samples();</a>
<a name="861"><span class="lineNum">     861 </span>            :         plumed_assert((samples-&gt;names() == std::vector&lt;std::string&gt;{&quot;system&quot;, &quot;atom&quot;}));</a>
<a name="862"><span class="lineNum">     862 </span>            : </a>
<a name="863"><span class="lineNum">     863 </span>            :         auto samples_values = samples-&gt;values().to(torch::kCPU);</a>
<a name="864"><span class="lineNum">     864 </span>            :         auto selected_atoms = this-&gt;evaluations_options_-&gt;get_selected_atoms();</a>
<a name="865"><span class="lineNum">     865 </span>            : </a>
<a name="866"><span class="lineNum">     866 </span>            :         // see above for an explanation of why we use this function</a>
<a name="867"><span class="lineNum">     867 </span>            :         auto get_output_location = [&amp;](unsigned i) {</a>
<a name="868"><span class="lineNum">     868 </span>            :             if (selected_atoms.has_value()) {</a>
<a name="869"><span class="lineNum">     869 </span>            :                 auto sample = samples_values.index({static_cast&lt;int64_t&gt;(i), torch::indexing::Slice()});</a>
<a name="870"><span class="lineNum">     870 </span>            :                 auto position = selected_atoms.value()-&gt;position(sample);</a>
<a name="871"><span class="lineNum">     871 </span>            :                 plumed_assert(position.has_value());</a>
<a name="872"><span class="lineNum">     872 </span>            :                 return static_cast&lt;unsigned&gt;(position.value());</a>
<a name="873"><span class="lineNum">     873 </span>            :             } else {</a>
<a name="874"><span class="lineNum">     874 </span>            :                 return static_cast&lt;unsigned&gt;(samples_values[i][1].item&lt;int32_t&gt;());</a>
<a name="875"><span class="lineNum">     875 </span>            :             }</a>
<a name="876"><span class="lineNum">     876 </span>            :         };</a>
<a name="877"><span class="lineNum">     877 </span>            : </a>
<a name="878"><span class="lineNum">     878 </span>            :         if (n_properties_ == 1) {</a>
<a name="879"><span class="lineNum">     879 </span>            :             for (unsigned i=0; i&lt;n_samples_; i++) {</a>
<a name="880"><span class="lineNum">     880 </span>            :                 auto output_i = get_output_location(i);</a>
<a name="881"><span class="lineNum">     881 </span>            :                 output_grad[i][0] = value-&gt;getForce(output_i);</a>
<a name="882"><span class="lineNum">     882 </span>            :             }</a>
<a name="883"><span class="lineNum">     883 </span>            :         } else {</a>
<a name="884"><span class="lineNum">     884 </span>            :             for (unsigned i=0; i&lt;n_samples_; i++) {</a>
<a name="885"><span class="lineNum">     885 </span>            :                 auto output_i = get_output_location(i);</a>
<a name="886"><span class="lineNum">     886 </span>            :                 for (unsigned j=0; j&lt;n_properties_; j++) {</a>
<a name="887"><span class="lineNum">     887 </span>            :                     output_grad[i][j] = value-&gt;getForce(output_i * n_properties_ + j);</a>
<a name="888"><span class="lineNum">     888 </span>            :                 }</a>
<a name="889"><span class="lineNum">     889 </span>            :             }</a>
<a name="890"><span class="lineNum">     890 </span>            :         }</a>
<a name="891"><span class="lineNum">     891 </span>            :     }</a>
<a name="892"><span class="lineNum">     892 </span>            : </a>
<a name="893"><span class="lineNum">     893 </span>            :     this-&gt;system_-&gt;positions().mutable_grad() = torch::Tensor();</a>
<a name="894"><span class="lineNum">     894 </span>            :     this-&gt;strain_.mutable_grad() = torch::Tensor();</a>
<a name="895"><span class="lineNum">     895 </span>            : </a>
<a name="896"><span class="lineNum">     896 </span>            :     torch_values.backward(output_grad);</a>
<a name="897"><span class="lineNum">     897 </span>            :     auto positions_grad = this-&gt;system_-&gt;positions().grad();</a>
<a name="898"><span class="lineNum">     898 </span>            :     auto strain_grad = this-&gt;strain_.grad();</a>
<a name="899"><span class="lineNum">     899 </span>            : </a>
<a name="900"><span class="lineNum">     900 </span>            :     positions_grad = positions_grad.to(torch::kCPU).to(torch::kFloat64);</a>
<a name="901"><span class="lineNum">     901 </span>            :     strain_grad = strain_grad.to(torch::kCPU).to(torch::kFloat64);</a>
<a name="902"><span class="lineNum">     902 </span>            : </a>
<a name="903"><span class="lineNum">     903 </span>            :     plumed_assert(positions_grad.sizes().size() == 2);</a>
<a name="904"><span class="lineNum">     904 </span>            :     plumed_assert(positions_grad.is_contiguous());</a>
<a name="905"><span class="lineNum">     905 </span>            : </a>
<a name="906"><span class="lineNum">     906 </span>            :     plumed_assert(strain_grad.sizes().size() == 2);</a>
<a name="907"><span class="lineNum">     907 </span>            :     plumed_assert(strain_grad.is_contiguous());</a>
<a name="908"><span class="lineNum">     908 </span>            : </a>
<a name="909"><span class="lineNum">     909 </span>            :     auto derivatives = std::vector&lt;double&gt;(</a>
<a name="910"><span class="lineNum">     910 </span>            :         positions_grad.data_ptr&lt;double&gt;(),</a>
<a name="911"><span class="lineNum">     911 </span>            :         positions_grad.data_ptr&lt;double&gt;() + 3 * this-&gt;system_-&gt;size()</a>
<a name="912"><span class="lineNum">     912 </span>            :     );</a>
<a name="913"><span class="lineNum">     913 </span>            : </a>
<a name="914"><span class="lineNum">     914 </span>            :     // add virials to the derivatives</a>
<a name="915"><span class="lineNum">     915 </span>            :     derivatives.push_back(-strain_grad[0][0].item&lt;double&gt;());</a>
<a name="916"><span class="lineNum">     916 </span>            :     derivatives.push_back(-strain_grad[0][1].item&lt;double&gt;());</a>
<a name="917"><span class="lineNum">     917 </span>            :     derivatives.push_back(-strain_grad[0][2].item&lt;double&gt;());</a>
<a name="918"><span class="lineNum">     918 </span>            : </a>
<a name="919"><span class="lineNum">     919 </span>            :     derivatives.push_back(-strain_grad[1][0].item&lt;double&gt;());</a>
<a name="920"><span class="lineNum">     920 </span>            :     derivatives.push_back(-strain_grad[1][1].item&lt;double&gt;());</a>
<a name="921"><span class="lineNum">     921 </span>            :     derivatives.push_back(-strain_grad[1][2].item&lt;double&gt;());</a>
<a name="922"><span class="lineNum">     922 </span>            : </a>
<a name="923"><span class="lineNum">     923 </span>            :     derivatives.push_back(-strain_grad[2][0].item&lt;double&gt;());</a>
<a name="924"><span class="lineNum">     924 </span>            :     derivatives.push_back(-strain_grad[2][1].item&lt;double&gt;());</a>
<a name="925"><span class="lineNum">     925 </span>            :     derivatives.push_back(-strain_grad[2][2].item&lt;double&gt;());</a>
<a name="926"><span class="lineNum">     926 </span>            : </a>
<a name="927"><span class="lineNum">     927 </span>            :     unsigned index = 0;</a>
<a name="928"><span class="lineNum">     928 </span>            :     this-&gt;setForcesOnAtoms(derivatives, index);</a>
<a name="929"><span class="lineNum">     929 </span>            : }</a>
<a name="930"><span class="lineNum">     930 </span>            : </a>
<a name="931"><span class="lineNum">     931 </span>            : } // namespace metatensor</a>
<a name="932"><span class="lineNum">     932 </span>            : } // namespace PLMD</a>
<a name="933"><span class="lineNum">     933 </span>            : </a>
<a name="934"><span class="lineNum">     934 </span>            : </a>
<a name="935"><span class="lineNum">     935 </span>            : #endif</a>
<a name="936"><span class="lineNum">     936 </span>            : </a>
<a name="937"><span class="lineNum">     937 </span>            : </a>
<a name="938"><span class="lineNum">     938 </span>            : namespace PLMD {</a>
<a name="939"><span class="lineNum">     939 </span>            : namespace metatensor {</a>
<a name="940"><span class="lineNum">     940 </span>            : </a>
<a name="941"><span class="lineNum">     941 </span>            : // use the same implementation for both the actual action and the dummy one</a>
<a name="942"><span class="lineNum">     942 </span>            : // (when libtorch and libmetatensor could not be found).</a>
<a name="943"><span class="lineNum">     943 </span><span class="lineCov">          2 : void MetatensorPlumedAction::registerKeywords(Keywords&amp; keys) {</span></a>
<a name="944"><span class="lineNum">     944 </span><span class="lineCov">          2 :     Action::registerKeywords(keys);</span></a>
<a name="945"><span class="lineNum">     945 </span><span class="lineCov">          2 :     ActionAtomistic::registerKeywords(keys);</span></a>
<a name="946"><span class="lineNum">     946 </span><span class="lineCov">          2 :     ActionWithValue::registerKeywords(keys);</span></a>
<a name="947"><span class="lineNum">     947 </span>            : </a>
<a name="948"><span class="lineNum">     948 </span><span class="lineCov">          4 :     keys.add(&quot;compulsory&quot;, &quot;MODEL&quot;, &quot;path to the exported metatensor model&quot;);</span></a>
<a name="949"><span class="lineNum">     949 </span><span class="lineCov">          4 :     keys.add(&quot;optional&quot;, &quot;EXTENSIONS_DIRECTORY&quot;, &quot;path to the directory containing TorchScript extensions to load&quot;);</span></a>
<a name="950"><span class="lineNum">     950 </span><span class="lineCov">          4 :     keys.add(&quot;optional&quot;, &quot;DEVICE&quot;, &quot;Torch device to use for the calculation&quot;);</span></a>
<a name="951"><span class="lineNum">     951 </span>            : </a>
<a name="952"><span class="lineNum">     952 </span><span class="lineCov">          4 :     keys.addFlag(&quot;CHECK_CONSISTENCY&quot;, false, &quot;Should we enable internal consistency of the model&quot;);</span></a>
<a name="953"><span class="lineNum">     953 </span>            : </a>
<a name="954"><span class="lineNum">     954 </span><span class="lineCov">          4 :     keys.add(&quot;numbered&quot;, &quot;SPECIES&quot;, &quot;the atoms in each PLUMED species&quot;);</span></a>
<a name="955"><span class="lineNum">     955 </span><span class="lineCov">          4 :     keys.reset_style(&quot;SPECIES&quot;, &quot;atoms&quot;);</span></a>
<a name="956"><span class="lineNum">     956 </span>            : </a>
<a name="957"><span class="lineNum">     957 </span><span class="lineCov">          4 :     keys.add(&quot;optional&quot;, &quot;SELECTED_ATOMS&quot;, &quot;subset of atoms that should be used for the calculation&quot;);</span></a>
<a name="958"><span class="lineNum">     958 </span><span class="lineCov">          4 :     keys.reset_style(&quot;SELECTED_ATOMS&quot;, &quot;atoms&quot;);</span></a>
<a name="959"><span class="lineNum">     959 </span>            : </a>
<a name="960"><span class="lineNum">     960 </span><span class="lineCov">          4 :     keys.add(&quot;optional&quot;, &quot;SPECIES_TO_TYPES&quot;, &quot;mapping from PLUMED SPECIES to metatensor's atomic types&quot;);</span></a>
<a name="961"><span class="lineNum">     961 </span>            : </a>
<a name="962"><span class="lineNum">     962 </span><span class="lineCov">          4 :     keys.addOutputComponent(&quot;outputs&quot;, &quot;default&quot;, &quot;collective variable created by the metatensor model&quot;);</span></a>
<a name="963"><span class="lineNum">     963 </span>            : </a>
<a name="964"><span class="lineNum">     964 </span><span class="lineCov">          2 :     keys.setValueDescription(&quot;collective variable created by the metatensor model&quot;);</span></a>
<a name="965"><span class="lineNum">     965 </span><span class="lineCov">          2 : }</span></a>
<a name="966"><span class="lineNum">     966 </span>            : </a>
<a name="967"><span class="lineNum">     967 </span>            : PLUMED_REGISTER_ACTION(MetatensorPlumedAction, &quot;METATENSOR&quot;)</a>
<a name="968"><span class="lineNum">     968 </span>            : </a>
<a name="969"><span class="lineNum">     969 </span>            : } // namespace metatensor</a>
<a name="970"><span class="lineNum">     970 </span>            : } // namespace PLMD</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="https://github.com/linux-test-project/lcov" target="_parent">LCOV version 1.16</a></td></tr>
  </table>
  <br>

</body>
</html>
